{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Sum-base\n",
    "Draft version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/junwenbu/opt/anaconda3/envs/sum/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/junwenbu/opt/anaconda3/envs/sum/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/junwenbu/opt/anaconda3/envs/sum/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/junwenbu/opt/anaconda3/envs/sum/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/junwenbu/opt/anaconda3/envs/sum/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/junwenbu/opt/anaconda3/envs/sum/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/junwenbu/opt/anaconda3/envs/sum/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/junwenbu/opt/anaconda3/envs/sum/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/junwenbu/opt/anaconda3/envs/sum/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/junwenbu/opt/anaconda3/envs/sum/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/junwenbu/opt/anaconda3/envs/sum/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/junwenbu/opt/anaconda3/envs/sum/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import time\n",
    "import nltk\n",
    "from tensorflow.python.layers.core import Dense\n",
    "from tensorflow.python.ops.rnn_cell_impl import _zero_state_tensors\n",
    "import logging\n",
    "import os\n",
    "from tensorboardX import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikihow = pd.read_csv(\"data/clean_wikihow.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summary</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sell yourself first</td>\n",
       "      <td>anything else stop sum artist think translate ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>read the classics before 1600</td>\n",
       "      <td>reading classics first thing well read want bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>join online artist communities</td>\n",
       "      <td>depending scale intend sell art pieces may wan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>make yourself public</td>\n",
       "      <td>get best advertising publish example pieces ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blog about your artwork</td>\n",
       "      <td>given hundreds free blogging websites lot choi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           summary  \\\n",
       "0             sell yourself first    \n",
       "1   read the classics before 1600    \n",
       "2  join online artist communities    \n",
       "3            make yourself public    \n",
       "4         blog about your artwork    \n",
       "\n",
       "                                                text  \n",
       "0  anything else stop sum artist think translate ...  \n",
       "1  reading classics first thing well read want bu...  \n",
       "2  depending scale intend sell art pieces may wan...  \n",
       "3  get best advertising publish example pieces ar...  \n",
       "4  given hundreds free blogging websites lot choi...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wikihow.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make sure the settings are the same as your training script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1212030 (1212030, 2)\n"
     ]
    }
   ],
   "source": [
    "summaries = wikihow['summary'].tolist()\n",
    "texts = wikihow['text'].tolist()\n",
    "print(len(summaries), wikihow.shape)\n",
    "\n",
    "# dataset range\n",
    "si, ei = 0, 10\n",
    "# Subset the data for training\n",
    "start = 0 #0\n",
    "end = start + 10 #20000\n",
    "\n",
    "summaries = summaries[si:ei]\n",
    "texts = texts[si:ei]\n",
    "\n",
    "# Set the Hyperparameters\n",
    "epochs = 100\n",
    "batch_size= 4 #64\n",
    "rnn_size = 256\n",
    "num_layers = 2\n",
    "learning_rate = 0.005\n",
    "keep_probability = 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_words(count_dict, text):\n",
    "    '''Count the number of occurrences of each word in a set of text'''\n",
    "    for sentence in text:\n",
    "        for word in str(sentence).split():\n",
    "            if word not in count_dict:\n",
    "                count_dict[word] = 1\n",
    "            else:\n",
    "                count_dict[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of Vocabulary: 573\n"
     ]
    }
   ],
   "source": [
    "# Find the number of times each word was used and the size of the vocabulary\n",
    "word_counts = {}\n",
    "\n",
    "count_words(word_counts, summaries)\n",
    "count_words(word_counts, texts)\n",
    "            \n",
    "print(\"Size of Vocabulary:\", len(word_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word embeddings: 516783\n"
     ]
    }
   ],
   "source": [
    "# Load Conceptnet Numberbatch's (CN) embeddings, similar to GloVe, but probably better \n",
    "# (https://github.com/commonsense/conceptnet-numberbatch)\n",
    "embeddings_index = {}\n",
    "with open('numberbatch-en-19.08.txt', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        values = line.split(' ')\n",
    "        word = values[0]\n",
    "        embedding = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = embedding\n",
    "\n",
    "print('Word embeddings:', len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words missing from CN: 0\n",
      "Percent of words that are missing from vocabulary: 0.0%\n"
     ]
    }
   ],
   "source": [
    "# Find the number of words that are missing from CN, and are used more than our threshold.\n",
    "missing_words = 0\n",
    "threshold = 10\n",
    "\n",
    "for word, count in word_counts.items():\n",
    "    if count > threshold:\n",
    "        if word not in embeddings_index:\n",
    "            missing_words += 1\n",
    "            \n",
    "missing_ratio = round(missing_words/len(word_counts),4)*100\n",
    "            \n",
    "print(\"Number of words missing from CN:\", missing_words)\n",
    "print(\"Percent of words that are missing from vocabulary: {}%\".format(missing_ratio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of unique words: 573\n",
      "Number of words we will use: 554\n",
      "Percent of words we will use: 96.67999999999999%\n"
     ]
    }
   ],
   "source": [
    "# Limit the vocab that we will use to words that appear ≥ threshold or are in GloVe\n",
    "\n",
    "#dictionary to convert words to integers\n",
    "vocab_to_int = {} \n",
    "\n",
    "value = 0\n",
    "for word, count in word_counts.items():\n",
    "    if count >= threshold or word in embeddings_index:\n",
    "        vocab_to_int[word] = value\n",
    "        value += 1\n",
    "\n",
    "# Special tokens that will be added to our vocab\n",
    "codes = [\"<UNK>\",\"<PAD>\",\"<EOS>\",\"<GO>\"]   \n",
    "\n",
    "# Add codes to vocab\n",
    "for code in codes:\n",
    "    vocab_to_int[code] = len(vocab_to_int)\n",
    "\n",
    "# Dictionary to convert integers to words\n",
    "int_to_vocab = {}\n",
    "for word, value in vocab_to_int.items():\n",
    "    int_to_vocab[value] = word\n",
    "\n",
    "usage_ratio = round(len(vocab_to_int) / len(word_counts),4)*100\n",
    "\n",
    "print(\"Total number of unique words:\", len(word_counts))\n",
    "print(\"Number of words we will use:\", len(vocab_to_int))\n",
    "print(\"Percent of words we will use: {}%\".format(usage_ratio))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_seq(text):\n",
    "    '''Prepare the text for the model'''\n",
    "    return [vocab_to_int.get(word, vocab_to_int['<UNK>']) for word in text.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/best_model.ckpt\n",
      "\n",
      "==================== Example 0 ====================\n",
      "Original Text:\n",
      "anything else stop sum artist think translate online profile words twitter allows entire page indulgence website would allow bring salient features creativity experience passion reasons painting make clear readers artist loves art produces high quality art true champion art great words find friend help really important aspect selling online – establishment credibility reliability\n",
      "\n",
      "Original Summary:\n",
      "sell yourself first \n",
      "\n",
      "Input:\n",
      "Word Ids: [46, 47, 48, 49, 9, 50, 51, 8, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 11, 70, 71, 9, 72, 29, 73, 74, 75, 29, 76, 77, 29, 78, 53, 79, 80, 81, 82, 83, 84, 85, 8, 550, 86, 87, 88]\n",
      "anything else stop sum artist think translate online profile words twitter allows entire page indulgence website would allow bring salient features creativity experience passion reasons painting make clear readers artist loves art produces high quality art true champion art great words find friend help really important aspect selling online <UNK> establishment credibility reliability\n",
      "\n",
      "Output Summary:\n",
      "Word Ids: [0, 1, 2]\n",
      "sell yourself first\n",
      "\n",
      "==================== Example 1 ====================\n",
      "Original Text:\n",
      "reading classics first thing well read want build solid foundation understanding books read cannot avoid earliest plays poems oral tales ever written remember novel really get popular 18th century find novels list without reading poetry homer plays sophocles able call well read list get started epic gilgamesh unknown author 18th – 17th century bce iliad odyssey homer 850–750 bce 8th century bce oresteia aeschylus 458 bce oedipus king sophocles 430 bce medea euripides 431 bce aeneid virgil 29–19 bce one thousand one nights unknown author 700–1500 beowulf unknown author 975 1025 tale genji murasaki shikibu 11th century divine comedy dante 1265–1321 decameron boccaccio 1349–53 canterbury tales chaucer 14th century\n",
      "\n",
      "Original Summary:\n",
      "read the classics before 1600 \n",
      "\n",
      "Input:\n",
      "Word Ids: [89, 5, 2, 90, 91, 3, 92, 93, 94, 95, 96, 97, 3, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 82, 109, 110, 550, 111, 79, 112, 20, 113, 89, 114, 115, 101, 116, 117, 118, 91, 3, 20, 109, 119, 120, 121, 122, 123, 550, 550, 550, 111, 124, 125, 126, 115, 550, 124, 127, 111, 124, 550, 128, 550, 124, 129, 130, 116, 550, 124, 131, 132, 550, 124, 133, 134, 550, 124, 135, 136, 135, 137, 122, 123, 550, 138, 122, 123, 550, 550, 139, 140, 141, 550, 550, 111, 142, 143, 144, 550, 145, 146, 550, 147, 104, 148, 550, 111]\n",
      "reading classics first thing well read want build solid foundation understanding books read cannot avoid earliest plays poems oral tales ever written remember novel really get popular <UNK> century find novels list without reading poetry homer plays sophocles able call well read list get started epic gilgamesh unknown author <UNK> <UNK> <UNK> century bce iliad odyssey homer <UNK> bce 8th century bce <UNK> aeschylus <UNK> bce oedipus king sophocles <UNK> bce medea euripides <UNK> bce aeneid virgil <UNK> bce one thousand one nights unknown author <UNK> beowulf unknown author <UNK> <UNK> tale genji murasaki <UNK> <UNK> century divine comedy dante <UNK> decameron boccaccio <UNK> canterbury tales chaucer <UNK> century\n",
      "\n",
      "Output Summary:\n",
      "Word Ids: [3, 4, 5, 6, 550, 550]\n",
      "read the classics before <UNK> <UNK>\n",
      "\n",
      "==================== Example 2 ====================\n",
      "Original Text:\n",
      "depending scale intend sell art pieces may want get account online art community store like deviant art 15 20 brokerage also find many online art galleries like art brokerage diva art group saatchi art show artwork online sell buyer completely secured transaction also many possible sites etsy heavier crafts still arty ebay auction site amazon store online store platform cafepress printing artwork onto stuff like mugs craigslist general classifieds quite lot artwork based sales sites general search read terms conditions every site carefully know commission percentage site takes know protections lack site offers know clientele generally peruse site know general sales brought site know everything relevant sales goal turn art investment property selling online likely much longer path end largely generally difficult unknown artists secure higher priced sales serious collectors online traditional gallery concrete decisions made safely best see selling art online adjunct usual methods selling art means\n",
      "\n",
      "Original Summary:\n",
      "join online artist communities \n",
      "\n",
      "Input:\n",
      "Word Ids: [149, 150, 151, 0, 29, 152, 153, 92, 109, 154, 8, 29, 155, 156, 157, 158, 29, 550, 550, 159, 160, 79, 161, 8, 29, 162, 157, 29, 159, 163, 29, 164, 550, 29, 165, 16, 8, 0, 166, 167, 168, 169, 160, 161, 170, 171, 172, 173, 174, 175, 176, 177, 178, 35, 179, 156, 8, 156, 180, 550, 181, 16, 182, 183, 157, 184, 185, 186, 187, 188, 43, 16, 189, 190, 171, 186, 191, 3, 192, 193, 194, 35, 195, 196, 197, 198, 35, 199, 196, 200, 201, 35, 202, 196, 203, 204, 205, 35, 196, 186, 190, 206, 35, 196, 207, 208, 190, 209, 210, 29, 211, 212, 85, 8, 213, 214, 215, 216, 217, 218, 204, 219, 122, 220, 221, 222, 223, 190, 224, 225, 8, 226, 227, 228, 229, 230, 231, 232, 233, 85, 29, 8, 234, 235, 236, 85, 29, 237]\n",
      "depending scale intend sell art pieces may want get account online art community store like deviant art <UNK> <UNK> brokerage also find many online art galleries like art brokerage diva art group <UNK> art show artwork online sell buyer completely secured transaction also many possible sites etsy heavier crafts still arty ebay auction site amazon store online store platform <UNK> printing artwork onto stuff like mugs craigslist general classifieds quite lot artwork based sales sites general search read terms conditions every site carefully know commission percentage site takes know protections lack site offers know clientele generally peruse site know general sales brought site know everything relevant sales goal turn art investment property selling online likely much longer path end largely generally difficult unknown artists secure higher priced sales serious collectors online traditional gallery concrete decisions made safely best see selling art online adjunct usual methods selling art means\n",
      "\n",
      "Output Summary:\n",
      "Word Ids: [36, 37, 26, 24, 18]\n",
      "expect this to be a\n",
      "\n",
      "==================== Example 3 ====================\n",
      "Original Text:\n",
      "get best advertising publish example pieces around web show demonstrate style sure add watermark digital version protect artwork art thieves spend little time researching online ways artists promoting works like promotional strategies want avoid type research give lot ideas also alert potential pitfalls ways promote artwork bookmark sites artists selling online really inspire come back regularly see evolving succeeding seize power twitter facebook increase people knowledge tweet updates new paintings thoughts art news items art general facebook place photos artwork digitally watermarked photos receiving awards information art artwork general perhaps even critiques artwork\n",
      "\n",
      "Original Summary:\n",
      "make yourself public \n",
      "\n",
      "Input:\n",
      "Word Ids: [109, 232, 238, 239, 240, 152, 241, 242, 165, 243, 244, 25, 245, 246, 247, 248, 249, 16, 29, 250, 251, 252, 253, 254, 8, 255, 220, 256, 257, 157, 258, 259, 92, 99, 260, 261, 262, 43, 263, 160, 264, 265, 266, 255, 267, 16, 268, 171, 220, 85, 8, 82, 269, 270, 271, 272, 233, 273, 274, 275, 276, 54, 277, 278, 279, 280, 281, 282, 283, 284, 285, 29, 286, 287, 29, 186, 277, 288, 289, 16, 290, 291, 289, 292, 293, 294, 29, 16, 186, 295, 296, 297, 16]\n",
      "get best advertising publish example pieces around web show demonstrate style sure add watermark digital version protect artwork art thieves spend little time researching online ways artists promoting works like promotional strategies want avoid type research give lot ideas also alert potential pitfalls ways promote artwork bookmark sites artists selling online really inspire come back regularly see evolving succeeding seize power twitter facebook increase people knowledge tweet updates new paintings thoughts art news items art general facebook place photos artwork digitally watermarked photos receiving awards information art artwork general perhaps even critiques artwork\n",
      "\n",
      "Output Summary:\n",
      "Word Ids: [11, 1, 12]\n",
      "make yourself public\n"
     ]
    }
   ],
   "source": [
    "tests = [0, 1, 2, 3]\n",
    "\n",
    "checkpoint = \"checkpoints/best_model.ckpt\"\n",
    "\n",
    "loaded_graph = tf.Graph()\n",
    "with tf.Session(graph=loaded_graph) as sess:\n",
    "    # Load saved model\n",
    "    loader = tf.train.import_meta_graph(checkpoint + '.meta')\n",
    "    loader.restore(sess, checkpoint)\n",
    "\n",
    "    input_data = loaded_graph.get_tensor_by_name('input:0')\n",
    "    logits = loaded_graph.get_tensor_by_name('predictions:0')\n",
    "    text_length = loaded_graph.get_tensor_by_name('text_length:0')\n",
    "    summary_length = loaded_graph.get_tensor_by_name('summary_length:0')\n",
    "    keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
    "    for t in tests:\n",
    "        text = text_to_seq(texts[t])\n",
    "        #Multiply by batch_size to match the model's input parameters\n",
    "        answer_logits = sess.run(logits, {input_data: [text]*batch_size, \n",
    "                                      summary_length: [np.random.randint(5,8)], \n",
    "                                      text_length: [len(text)]*batch_size,\n",
    "                                      keep_prob: 1.0})[0] \n",
    "\n",
    "        # Remove the padding from the tweet\n",
    "        pad = vocab_to_int[\"<PAD>\"]\n",
    "        # print('Original Text:', wikihow.text[random])\n",
    "        # print('Original summary:', wikihow.summary[random])#clean_summaries[random]\n",
    "        print('\\n==================== Example {} ===================='.format(t))\n",
    "        print('Original Text:')\n",
    "        print(texts[t])\n",
    "        print('\\nOriginal Summary:')\n",
    "        print(summaries[t])\n",
    "        print('\\nInput:')\n",
    "        print('Word Ids: {}'.format([i for i in text]))\n",
    "        print('{}'.format(\" \".join([int_to_vocab[i] for i in text])))\n",
    "        print('\\nOutput Summary:')\n",
    "        print('Word Ids: {}'.format([i for i in answer_logits if i != pad]))\n",
    "        print('{}'.format(\" \".join([int_to_vocab[i] for i in answer_logits if i != pad])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
