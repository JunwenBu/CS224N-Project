{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Local Check (Draft) - Check Code and Overfit\n",
    "This is a draft. Currently, it is mainly used for debugging.\n",
    "\n",
    "Overfitted a small subset. Tests show the model works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\envs\\sum\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\anaconda3\\envs\\sum\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\anaconda3\\envs\\sum\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\anaconda3\\envs\\sum\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\anaconda3\\envs\\sum\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\anaconda3\\envs\\sum\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\anaconda3\\envs\\sum\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\anaconda3\\envs\\sum\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\anaconda3\\envs\\sum\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\anaconda3\\envs\\sum\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\anaconda3\\envs\\sum\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\anaconda3\\envs\\sum\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import time\n",
    "import nltk\n",
    "from tensorflow.python.layers.core import Dense\n",
    "from tensorflow.python.ops.rnn_cell_impl import _zero_state_tensors\n",
    "import logging\n",
    "import os\n",
    "from tensorboardX import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikihow = pd.read_csv(\"data/clean_wikihow.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summary</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sell yourself first</td>\n",
       "      <td>anything else stop sum artist think translate ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>read the classics before 1600</td>\n",
       "      <td>reading classics first thing well read want bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>join online artist communities</td>\n",
       "      <td>depending scale intend sell art pieces may wan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>make yourself public</td>\n",
       "      <td>get best advertising publish example pieces ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blog about your artwork</td>\n",
       "      <td>given hundreds free blogging websites lot choi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           summary  \\\n",
       "0             sell yourself first    \n",
       "1   read the classics before 1600    \n",
       "2  join online artist communities    \n",
       "3            make yourself public    \n",
       "4         blog about your artwork    \n",
       "\n",
       "                                                text  \n",
       "0  anything else stop sum artist think translate ...  \n",
       "1  reading classics first thing well read want bu...  \n",
       "2  depending scale intend sell art pieces may wan...  \n",
       "3  get best advertising publish example pieces ar...  \n",
       "4  given hundreds free blogging websites lot choi...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wikihow.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1212030 (1212030, 2)\n"
     ]
    }
   ],
   "source": [
    "summaries = wikihow['summary'].tolist()\n",
    "texts = wikihow['text'].tolist()\n",
    "print(len(summaries), wikihow.shape)\n",
    "\n",
    "# dataset range\n",
    "si, ei = 0, 20\n",
    "# Subset the data for training\n",
    "start = 0 #0\n",
    "end = start + 20 #20000\n",
    "\n",
    "summaries = summaries[si:ei]\n",
    "texts = texts[si:ei]\n",
    "\n",
    "# Set the Hyperparameters\n",
    "epochs = 100\n",
    "batch_size= 4 #64\n",
    "rnn_size = 256\n",
    "num_layers = 2\n",
    "learning_rate = 0.005\n",
    "keep_probability = 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_words(count_dict, text):\n",
    "    '''Count the number of occurrences of each word in a set of text'''\n",
    "    for sentence in text:\n",
    "        for word in str(sentence).split():\n",
    "            if word not in count_dict:\n",
    "                count_dict[word] = 1\n",
    "            else:\n",
    "                count_dict[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of Vocabulary: 1239\n"
     ]
    }
   ],
   "source": [
    "# Find the number of times each word was used and the size of the vocabulary\n",
    "word_counts = {}\n",
    "\n",
    "count_words(word_counts, summaries)\n",
    "count_words(word_counts, texts)\n",
    "            \n",
    "print(\"Size of Vocabulary:\", len(word_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word embeddings: 516783\n"
     ]
    }
   ],
   "source": [
    "# Load Conceptnet Numberbatch's (CN) embeddings, similar to GloVe, but probably better \n",
    "# (https://github.com/commonsense/conceptnet-numberbatch)\n",
    "embeddings_index = {}\n",
    "with open('numberbatch-en-19.08.txt', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        values = line.split(' ')\n",
    "        word = values[0]\n",
    "        embedding = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = embedding\n",
    "\n",
    "print('Word embeddings:', len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words missing from CN: 0\n",
      "Percent of words that are missing from vocabulary: 0.0%\n"
     ]
    }
   ],
   "source": [
    "# Find the number of words that are missing from CN, and are used more than our threshold.\n",
    "missing_words = 0\n",
    "threshold = 10\n",
    "\n",
    "for word, count in word_counts.items():\n",
    "    if count > threshold:\n",
    "        if word not in embeddings_index:\n",
    "            missing_words += 1\n",
    "            \n",
    "missing_ratio = round(missing_words/len(word_counts),4)*100\n",
    "            \n",
    "print(\"Number of words missing from CN:\", missing_words)\n",
    "print(\"Percent of words that are missing from vocabulary: {}%\".format(missing_ratio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of unique words: 1239\n",
      "Number of words we will use: 1107\n",
      "Percent of words we will use: 89.35%\n"
     ]
    }
   ],
   "source": [
    "# Limit the vocab that we will use to words that appear ≥ threshold or are in GloVe\n",
    "\n",
    "#dictionary to convert words to integers\n",
    "vocab_to_int = {} \n",
    "\n",
    "value = 0\n",
    "for word, count in word_counts.items():\n",
    "    if count >= threshold or word in embeddings_index:\n",
    "        vocab_to_int[word] = value\n",
    "        value += 1\n",
    "\n",
    "# Special tokens that will be added to our vocab\n",
    "codes = [\"<UNK>\",\"<PAD>\",\"<EOS>\",\"<GO>\"]   \n",
    "\n",
    "# Add codes to vocab\n",
    "for code in codes:\n",
    "    vocab_to_int[code] = len(vocab_to_int)\n",
    "\n",
    "# Dictionary to convert integers to words\n",
    "int_to_vocab = {}\n",
    "for word, value in vocab_to_int.items():\n",
    "    int_to_vocab[value] = word\n",
    "\n",
    "usage_ratio = round(len(vocab_to_int) / len(word_counts),4)*100\n",
    "\n",
    "print(\"Total number of unique words:\", len(word_counts))\n",
    "print(\"Number of words we will use:\", len(vocab_to_int))\n",
    "print(\"Percent of words we will use: {}%\".format(usage_ratio))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Don't need for Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1107\n"
     ]
    }
   ],
   "source": [
    "# Need to use 300 for embedding dimensions to match CN's vectors.\n",
    "embedding_dim = 300\n",
    "nb_words = len(vocab_to_int)\n",
    "\n",
    "# Create matrix with default values of zero\n",
    "word_embedding_matrix = np.zeros((nb_words, embedding_dim), dtype=np.float32)\n",
    "for word, i in vocab_to_int.items():\n",
    "    if word in embeddings_index:\n",
    "        word_embedding_matrix[i] = embeddings_index[word]\n",
    "    else:\n",
    "        # If word not in CN, create a random embedding for it\n",
    "        new_embedding = np.array(np.random.uniform(-1.0, 1.0, embedding_dim))\n",
    "        embeddings_index[word] = new_embedding\n",
    "        word_embedding_matrix[i] = new_embedding\n",
    "\n",
    "# Check if value matches len(vocab_to_int)\n",
    "print(len(word_embedding_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_ints(text, word_count, unk_count, eos=False):\n",
    "    '''Convert words in text to an integer.\n",
    "       If word is not in vocab_to_int, use UNK's integer.\n",
    "       Total the number of words and UNKs.\n",
    "       Add EOS token to the end of texts'''\n",
    "    ints = []\n",
    "    for sentence in text:\n",
    "        sentence_ints = []\n",
    "        # some 'nan' in dataset, need to remove \n",
    "        if isinstance(sentence, float):\n",
    "            sentence = str(sentence)\n",
    "        for word in sentence.split():\n",
    "            word_count += 1\n",
    "            if word in vocab_to_int:\n",
    "                sentence_ints.append(vocab_to_int[word])\n",
    "            else:\n",
    "                sentence_ints.append(vocab_to_int[\"<UNK>\"])\n",
    "                unk_count += 1\n",
    "        if eos:\n",
    "            sentence_ints.append(vocab_to_int[\"<EOS>\"])\n",
    "        ints.append(sentence_ints)\n",
    "    return ints, word_count, unk_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of words in headlines: 2012\n",
      "Total number of UNKs in headlines: 164\n",
      "Percent of words that are UNK: 8.15%\n"
     ]
    }
   ],
   "source": [
    "# Apply convert_to_ints to clean_summaries and clean_texts\n",
    "word_count = 0\n",
    "unk_count = 0\n",
    "\n",
    "int_summaries, word_count, unk_count = convert_to_ints(summaries, word_count, unk_count)\n",
    "int_texts, word_count, unk_count = convert_to_ints(texts, word_count, unk_count, eos=True)\n",
    "\n",
    "unk_percent = round(unk_count/word_count,4)*100\n",
    "\n",
    "print(\"Total number of words in headlines:\", word_count)\n",
    "print(\"Total number of UNKs in headlines:\", unk_count)\n",
    "print(\"Percent of words that are UNK: {}%\".format(unk_percent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lengths(text):\n",
    "    '''Create a data frame of the sentence lengths from a text'''\n",
    "    lengths = []\n",
    "    for sentence in text:\n",
    "        lengths.append(len(sentence))\n",
    "    return pd.DataFrame(lengths, columns=['counts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths_summaries = create_lengths(int_summaries)\n",
    "lengths_texts = create_lengths(int_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unk_counter(sentence):\n",
    "    '''Counts the number of time UNK appears in a sentence.'''\n",
    "    unk_count = 0\n",
    "    for word in sentence:\n",
    "        if word == vocab_to_int[\"<UNK>\"]:\n",
    "            unk_count += 1\n",
    "    return unk_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of sorted summaries: 17\n",
      "Length of sorted texts: 17\n"
     ]
    }
   ],
   "source": [
    "# takes a long time  , this is normal\n",
    "\n",
    "# Sort the summaries and texts by the length of the texts, shortest to longest\n",
    "# Limit the length of summaries and texts based on the min and max ranges.\n",
    "# Remove reviews that include too many UNKs\n",
    "\n",
    "sorted_summaries = []\n",
    "sorted_texts = []\n",
    "max_text_length = 200\n",
    "max_summary_length = 20\n",
    "min_length = 3\n",
    "unk_text_limit = 20\n",
    "unk_summary_limit = 2\n",
    "\n",
    "for length in range(min(lengths_texts.counts), max_text_length): \n",
    "    for count, words in enumerate(int_summaries):\n",
    "        if (len(int_summaries[count]) >= min_length and\n",
    "            len(int_summaries[count]) <= max_summary_length and\n",
    "            len(int_texts[count]) >= min_length and\n",
    "            unk_counter(int_summaries[count]) <= unk_summary_limit and\n",
    "            unk_counter(int_texts[count]) <= unk_text_limit and\n",
    "            length == len(int_texts[count])\n",
    "           ):\n",
    "            sorted_summaries.append(int_summaries[count])\n",
    "            sorted_texts.append(int_texts[count])\n",
    "        \n",
    "# Compare lengths to ensure they match\n",
    "print('Length of sorted summaries:', len(sorted_summaries))\n",
    "print('Length of sorted texts:', len(sorted_texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_dict = {'summary':sorted_summaries, 'text':sorted_texts}\n",
    "df = pd.DataFrame(sorted_dict)\n",
    "df.to_csv('sorted.csv', index=False)\n",
    "# Copy it to data folder so that it can be used in the project later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summary</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[24, 25, 26, 27, 28, 15, 29]</td>\n",
       "      <td>[469, 29, 362, 470, 471, 472, 473, 474, 475, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[17, 18, 62, 63]</td>\n",
       "      <td>[655, 656, 657, 605, 658, 446, 659, 660, 590, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[53, 15, 54, 55, 18, 56]</td>\n",
       "      <td>[628, 280, 629, 630, 631, 632, 72, 633, 634, 6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[57, 58, 47, 15, 59, 60, 61]</td>\n",
       "      <td>[642, 282, 643, 644, 59, 60, 493, 111, 643, 22...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0, 1, 2]</td>\n",
       "      <td>[77, 78, 79, 80, 9, 81, 82, 8, 83, 84, 85, 86,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        summary  \\\n",
       "0  [24, 25, 26, 27, 28, 15, 29]   \n",
       "1              [17, 18, 62, 63]   \n",
       "2      [53, 15, 54, 55, 18, 56]   \n",
       "3  [57, 58, 47, 15, 59, 60, 61]   \n",
       "4                     [0, 1, 2]   \n",
       "\n",
       "                                                text  \n",
       "0  [469, 29, 362, 470, 471, 472, 473, 474, 475, 1...  \n",
       "1  [655, 656, 657, 605, 658, 446, 659, 660, 590, ...  \n",
       "2  [628, 280, 629, 630, 631, 632, 72, 633, 634, 6...  \n",
       "3  [642, 282, 643, 644, 59, 60, 493, 111, 643, 22...  \n",
       "4  [77, 78, 79, 80, 9, 81, 82, 8, 83, 84, 85, 86,...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_sum_text = pd.read_csv(\"sorted.csv\")\n",
    "print(sorted_sum_text.shape)\n",
    "sorted_sum_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[469, 29, 362, 470, 471, 472, 473, 474, 475, 112, 476, 477, 478, 479, 480, 1105] <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "# recover preprocessed item\n",
    "str_sorted_summaries = sorted_sum_text['summary'].tolist()\n",
    "str_sorted_texts = sorted_sum_text['text'].tolist()\n",
    "print(str_sorted_texts[0], type(str_sorted_summaries[0]))\n",
    "\n",
    "sorted_summaries = [[int(s) for s in l[1:-1].split(',')] for l in str_sorted_summaries]\n",
    "sorted_texts = [[int(s) for s in l[1:-1].split(',')] for l in str_sorted_texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Related"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_inputs():\n",
    "    '''Create palceholders for inputs to the model'''\n",
    "    input_data = tf.placeholder(tf.int32, [None, None], name='input')\n",
    "    targets = tf.placeholder(tf.int32, [None, None], name='targets')\n",
    "    lr = tf.placeholder(tf.float32, name='learning_rate')\n",
    "    keep_prob = tf.placeholder(tf.float32, name='keep_prob')\n",
    "    summary_length = tf.placeholder(tf.int32, (None,), name='summary_length')\n",
    "    max_summary_length = tf.reduce_max(summary_length, name='max_dec_len')\n",
    "    text_length = tf.placeholder(tf.int32, (None,), name='text_length')\n",
    "    return input_data, targets, lr, keep_prob, summary_length, max_summary_length, text_length\n",
    "\n",
    "\n",
    "def process_encoding_input(target_data, vocab_to_int, batch_size):\n",
    "    '''Remove the last word id from each batch and concat the <GO> to the begining of each batch'''\n",
    "    \n",
    "    ending = tf.strided_slice(target_data, [0, 0], [batch_size, -1], [1, 1])\n",
    "    dec_input = tf.concat([tf.fill([batch_size, 1], vocab_to_int['<GO>']), ending], 1)\n",
    "\n",
    "    return dec_input\n",
    "\n",
    "\n",
    "def encoding_layer(rnn_size, sequence_length, num_layers, rnn_inputs, keep_prob):\n",
    "    '''Create the encoding layer'''\n",
    "    \n",
    "    for layer in range(num_layers):\n",
    "        with tf.variable_scope('encoder_{}'.format(layer)):\n",
    "            cell_fw = tf.contrib.rnn.LSTMCell(rnn_size,\n",
    "                                              initializer=tf.random_uniform_initializer(-0.1, 0.1, seed=2))\n",
    "            cell_fw = tf.contrib.rnn.DropoutWrapper(cell_fw, \n",
    "                                                    input_keep_prob = keep_prob)\n",
    "\n",
    "            cell_bw = tf.contrib.rnn.LSTMCell(rnn_size,\n",
    "                                              initializer=tf.random_uniform_initializer(-0.1, 0.1, seed=2))\n",
    "            cell_bw = tf.contrib.rnn.DropoutWrapper(cell_bw, \n",
    "                                                    input_keep_prob = keep_prob)\n",
    "\n",
    "            enc_output, enc_state = tf.nn.bidirectional_dynamic_rnn(cell_fw, \n",
    "                                                                    cell_bw, \n",
    "                                                                    rnn_inputs,\n",
    "                                                                    sequence_length,\n",
    "                                                                    dtype=tf.float32)\n",
    "    # Join outputs since we are using a bidirectional RNN\n",
    "    enc_output = tf.concat(enc_output,2)\n",
    "    \n",
    "    return enc_output, enc_state\n",
    "\n",
    "\n",
    "def training_decoding_layer(dec_embed_input, summary_length, dec_cell, initial_state, output_layer, \n",
    "                            vocab_size, max_summary_length):\n",
    "    '''Create the training logits'''\n",
    "    \n",
    "    training_helper = tf.contrib.seq2seq.TrainingHelper(inputs=dec_embed_input,\n",
    "                                                        sequence_length=summary_length,\n",
    "                                                        time_major=False)\n",
    "\n",
    "    training_decoder = tf.contrib.seq2seq.BasicDecoder(dec_cell,\n",
    "                                                       training_helper,\n",
    "                                                       initial_state,\n",
    "                                                       output_layer) \n",
    "\n",
    "    training_logits, _ , _ = tf.contrib.seq2seq.dynamic_decode(training_decoder,\n",
    "                                                           output_time_major=False,\n",
    "                                                           impute_finished=True,\n",
    "                                                           maximum_iterations=max_summary_length)\n",
    "    return training_decoder\n",
    "\n",
    "\n",
    "def inference_decoding_layer(embeddings, start_token, end_token, dec_cell, initial_state, output_layer,\n",
    "                             max_summary_length, batch_size):\n",
    "    '''Create the inference logits'''\n",
    "    \n",
    "    start_tokens = tf.tile(tf.constant([start_token], dtype=tf.int32), [batch_size], name='start_tokens')\n",
    "    \n",
    "    inference_helper = tf.contrib.seq2seq.GreedyEmbeddingHelper(embeddings,\n",
    "                                                                start_tokens,\n",
    "                                                                end_token)\n",
    "                \n",
    "    inference_decoder = tf.contrib.seq2seq.BasicDecoder(dec_cell,\n",
    "                                                        inference_helper,\n",
    "                                                        initial_state,\n",
    "                                                        output_layer)\n",
    "                \n",
    "    inference_logits, _ , _ = tf.contrib.seq2seq.dynamic_decode(inference_decoder,\n",
    "                                                            output_time_major=False,\n",
    "                                                            impute_finished=True,\n",
    "                                                            maximum_iterations=max_summary_length)\n",
    "    \n",
    "    return inference_decoder\n",
    "\n",
    "\n",
    "def decoding_layer(dec_embed_input, embeddings, enc_output, enc_state, vocab_size, text_length, summary_length, \n",
    "                   max_summary_length, rnn_size, vocab_to_int, keep_prob, batch_size, num_layers):\n",
    "    '''Create the decoding cell and attention for the training and inference decoding layers'''\n",
    "    \n",
    "    for layer in range(num_layers):\n",
    "        with tf.variable_scope('decoder_{}'.format(layer)):\n",
    "            lstm = tf.contrib.rnn.LSTMCell(rnn_size,\n",
    "                                           initializer=tf.random_uniform_initializer(-0.1, 0.1, seed=2))\n",
    "            dec_cell = tf.contrib.rnn.DropoutWrapper(lstm, \n",
    "                                                     input_keep_prob = keep_prob)\n",
    "    \n",
    "    output_layer = Dense(vocab_size,\n",
    "                         kernel_initializer = tf.truncated_normal_initializer(mean = 0.0, stddev=0.1))\n",
    "    \n",
    "    attn_mech = tf.contrib.seq2seq.BahdanauAttention(rnn_size,\n",
    "                                                  enc_output,\n",
    "                                                  text_length,\n",
    "                                                  normalize=False,\n",
    "                                                  name='BahdanauAttention')\n",
    "\n",
    "    dec_cell = tf.contrib.seq2seq.AttentionWrapper(dec_cell,\n",
    "                                                          attn_mech,\n",
    "                                                          rnn_size)\n",
    "            \n",
    "    #initial_state = tf.contrib.seq2seq.AttentionWrapperState(enc_state[0],\n",
    "    #                                                                _zero_state_tensors(rnn_size, \n",
    "    #                                                                                    batch_size, \n",
    "    #                                                                                    tf.float32)) \n",
    "    initial_state = dec_cell.zero_state(batch_size=batch_size,dtype=tf.float32).clone(cell_state=enc_state[0])\n",
    "\n",
    "    with tf.variable_scope(\"decode\"):\n",
    "        training_decoder = training_decoding_layer(dec_embed_input, \n",
    "                                                  summary_length, \n",
    "                                                  dec_cell, \n",
    "                                                  initial_state,\n",
    "                                                  output_layer,\n",
    "                                                  vocab_size, \n",
    "                                                  max_summary_length)\n",
    "        \n",
    "        training_logits,_ ,_ = tf.contrib.seq2seq.dynamic_decode(training_decoder,\n",
    "                                  output_time_major=False,\n",
    "                                  impute_finished=True,\n",
    "                                  maximum_iterations=max_summary_length)\n",
    "    with tf.variable_scope(\"decode\", reuse=True):\n",
    "        inference_decoder = inference_decoding_layer(embeddings,  \n",
    "                                                    vocab_to_int['<GO>'], \n",
    "                                                    vocab_to_int['<EOS>'],\n",
    "                                                    dec_cell, \n",
    "                                                    initial_state, \n",
    "                                                    output_layer,\n",
    "                                                    max_summary_length,\n",
    "                                                    batch_size)\n",
    "        \n",
    "        inference_logits,_ ,_ = tf.contrib.seq2seq.dynamic_decode(inference_decoder,\n",
    "                                  output_time_major=False,\n",
    "                                  impute_finished=True,\n",
    "                                  maximum_iterations=max_summary_length)\n",
    "\n",
    "    return training_logits, inference_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2seq_model(input_data, target_data, keep_prob, text_length, summary_length, max_summary_length, \n",
    "                  vocab_size, rnn_size, num_layers, vocab_to_int, batch_size):\n",
    "    '''Use the previous functions to create the training and inference logits'''\n",
    "    \n",
    "    # Use Numberbatch's embeddings and the newly created ones as our embeddings\n",
    "    embeddings = word_embedding_matrix\n",
    "    \n",
    "    enc_embed_input = tf.nn.embedding_lookup(embeddings, input_data)\n",
    "    enc_output, enc_state = encoding_layer(rnn_size, text_length, num_layers, enc_embed_input, keep_prob)\n",
    "    \n",
    "    dec_input = process_encoding_input(target_data, vocab_to_int, batch_size)\n",
    "    dec_embed_input = tf.nn.embedding_lookup(embeddings, dec_input)\n",
    "    \n",
    "    training_logits, inference_logits  = decoding_layer(dec_embed_input, \n",
    "                                                        embeddings,\n",
    "                                                        enc_output,\n",
    "                                                        enc_state, \n",
    "                                                        vocab_size, \n",
    "                                                        text_length, \n",
    "                                                        summary_length, \n",
    "                                                        max_summary_length,\n",
    "                                                        rnn_size, \n",
    "                                                        vocab_to_int, \n",
    "                                                        keep_prob, \n",
    "                                                        batch_size,\n",
    "                                                        num_layers)\n",
    "    \n",
    "    return training_logits, inference_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sentence_batch(sentence_batch):\n",
    "    \"\"\"Pad sentences with <PAD> so that each sentence of a batch has the same length\"\"\"\n",
    "    max_sentence = max([len(sentence) for sentence in sentence_batch])\n",
    "    return [sentence + [vocab_to_int['<PAD>']] * (max_sentence - len(sentence)) for sentence in sentence_batch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batches(summaries, texts, batch_size):\n",
    "    \"\"\"Batch summaries, texts, and the lengths of their sentences together\"\"\"\n",
    "    for batch_i in range(0, len(texts)//batch_size):\n",
    "        start_i = batch_i * batch_size\n",
    "        summaries_batch = summaries[start_i:start_i + batch_size]\n",
    "        texts_batch = texts[start_i:start_i + batch_size]\n",
    "        pad_summaries_batch = np.array(pad_sentence_batch(summaries_batch))\n",
    "        pad_texts_batch = np.array(pad_sentence_batch(texts_batch))\n",
    "        \n",
    "        # Need the lengths for the _lengths parameters\n",
    "        pad_summaries_lengths = []\n",
    "        for summary in pad_summaries_batch:\n",
    "            pad_summaries_lengths.append(len(summary))\n",
    "        \n",
    "        pad_texts_lengths = []\n",
    "        for text in pad_texts_batch:\n",
    "            pad_texts_lengths.append(len(text))\n",
    "        \n",
    "        yield pad_summaries_batch, pad_texts_batch, pad_summaries_lengths, pad_texts_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From <ipython-input-20-039719670f60>:28: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From <ipython-input-20-039719670f60>:41: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n",
      "WARNING:tensorflow:From C:\\anaconda3\\envs\\sum\\lib\\site-packages\\tensorflow\\python\\ops\\rnn.py:464: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From C:\\anaconda3\\envs\\sum\\lib\\site-packages\\tensorflow\\python\\ops\\rnn_cell_impl.py:961: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x0000023CB5C684C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x0000023CB5C684C8>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x0000023CB5C684C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x0000023CB5C684C8>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:From C:\\anaconda3\\envs\\sum\\lib\\site-packages\\tensorflow\\python\\ops\\rnn.py:244: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x0000023CB7CD8E48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x0000023CB7CD8E48>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x0000023CB7CD8E48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x0000023CB7CD8E48>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x0000023CB5E03248>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x0000023CB5E03248>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x0000023CB5E03248>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x0000023CB5E03248>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x0000023CB7EE2548>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x0000023CB7EE2548>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x0000023CB7EE2548>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x0000023CB7EE2548>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:From C:\\anaconda3\\envs\\sum\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000023CB7E5AE08>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000023CB7E5AE08>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000023CB7E5AE08>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000023CB7E5AE08>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method AttentionWrapper.call of <tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper object at 0x0000023CB5E03248>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method AttentionWrapper.call of <tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper object at 0x0000023CB5E03248>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method AttentionWrapper.call of <tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper object at 0x0000023CB5E03248>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method AttentionWrapper.call of <tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper object at 0x0000023CB5E03248>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x0000023CB7F9D4C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x0000023CB7F9D4C8>>: AttributeError: module 'gast' has no attribute 'Num'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x0000023CB7F9D4C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x0000023CB7F9D4C8>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000023CB85BF3C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000023CB85BF3C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000023CB85BF3C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000023CB85BF3C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000023CB5E03348>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000023CB5E03348>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000023CB5E03348>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000023CB5E03348>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000023CB8510A48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000023CB8510A48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000023CB8510A48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000023CB8510A48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method AttentionWrapper.call of <tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper object at 0x0000023CB5E03248>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method AttentionWrapper.call of <tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper object at 0x0000023CB5E03248>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method AttentionWrapper.call of <tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper object at 0x0000023CB5E03248>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method AttentionWrapper.call of <tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper object at 0x0000023CB5E03248>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x0000023CB7F9D4C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x0000023CB7F9D4C8>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x0000023CB7F9D4C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x0000023CB7F9D4C8>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000023CB85BF3C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000023CB85BF3C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000023CB85BF3C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000023CB85BF3C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000023CB5E03348>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000023CB5E03348>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000023CB5E03348>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000023CB5E03348>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000023CB8510A48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000023CB8510A48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000023CB8510A48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000023CB8510A48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method AttentionWrapper.call of <tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper object at 0x0000023CB5E03248>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method AttentionWrapper.call of <tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper object at 0x0000023CB5E03248>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method AttentionWrapper.call of <tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper object at 0x0000023CB5E03248>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method AttentionWrapper.call of <tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper object at 0x0000023CB5E03248>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x0000023CB7F9D4C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x0000023CB7F9D4C8>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x0000023CB7F9D4C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x0000023CB7F9D4C8>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000023CB85BF3C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000023CB85BF3C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000023CB85BF3C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000023CB85BF3C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000023CB5E03348>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000023CB5E03348>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000023CB5E03348>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000023CB5E03348>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000023CB8510A48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000023CB8510A48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000023CB8510A48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000023CB8510A48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method AttentionWrapper.call of <tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper object at 0x0000023CB5E03248>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method AttentionWrapper.call of <tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper object at 0x0000023CB5E03248>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method AttentionWrapper.call of <tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper object at 0x0000023CB5E03248>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method AttentionWrapper.call of <tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper object at 0x0000023CB5E03248>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x0000023CB7F9D4C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x0000023CB7F9D4C8>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x0000023CB7F9D4C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x0000023CB7F9D4C8>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000023CB85BF3C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000023CB85BF3C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000023CB85BF3C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000023CB85BF3C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000023CB5E03348>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000023CB5E03348>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000023CB5E03348>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000023CB5E03348>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000023CB8510A48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000023CB8510A48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000023CB8510A48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000023CB8510A48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "Graph is built.\n"
     ]
    }
   ],
   "source": [
    "# Build the graph\n",
    "train_graph = tf.Graph()\n",
    "# Set the graph to default to ensure that it is ready for training\n",
    "with train_graph.as_default():\n",
    "    \n",
    "    # Load the model inputs    \n",
    "    input_data, targets, lr, keep_prob, summary_length, max_summary_length, text_length = model_inputs()\n",
    "\n",
    "    # Create the training and inference logits\n",
    "    training_logits, inference_logits = seq2seq_model(tf.reverse(input_data, [-1]),\n",
    "                                                      targets, \n",
    "                                                      keep_prob,   \n",
    "                                                      text_length,\n",
    "                                                      summary_length,\n",
    "                                                      max_summary_length,\n",
    "                                                      len(vocab_to_int)+1,\n",
    "                                                      rnn_size, \n",
    "                                                      num_layers, \n",
    "                                                      vocab_to_int,\n",
    "                                                      batch_size)\n",
    "    \n",
    "    # Create tensors for the training logits and inference logits\n",
    "    training_logits = tf.identity(training_logits.rnn_output, 'logits')\n",
    "    inference_logits = tf.identity(inference_logits.sample_id, name='predictions')\n",
    "    \n",
    "    # Create the weights for sequence_loss\n",
    "    masks = tf.sequence_mask(summary_length, max_summary_length, dtype=tf.float32, name='masks')\n",
    "\n",
    "    with tf.name_scope(\"optimization\"):\n",
    "        # Loss function\n",
    "        cost = tf.contrib.seq2seq.sequence_loss(\n",
    "            training_logits,\n",
    "            targets,\n",
    "            masks)\n",
    "\n",
    "        # Optimizer\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "\n",
    "        # Gradient Clipping\n",
    "        gradients = optimizer.compute_gradients(cost)\n",
    "        capped_gradients = [(tf.clip_by_value(grad, -5., 5.), var) for grad, var in gradients if grad is not None]\n",
    "        train_op = optimizer.apply_gradients(capped_gradients)\n",
    "print(\"Graph is built.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shortest text length: 7\n",
      "The longest text length: 8\n",
      "[30, 4, 31, 32, 33, 15, 34, 35]\n"
     ]
    }
   ],
   "source": [
    "sorted_summaries_short = sorted_summaries[start:end]\n",
    "sorted_texts_short = sorted_texts[start:end]\n",
    "print(\"The shortest text length:\", len(sorted_summaries_short[0]))\n",
    "print(\"The longest text length:\",len(sorted_summaries_short[-1]))\n",
    "print(sorted_summaries_short[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step:1 batch_loss:7.006857872009277\n",
      "Epoch   1/100 Batch    1/4 - Loss:  0.350, Seconds: 33.69\n",
      "Average loss for this update: 7.007\n",
      "New Record!\n",
      "Average loss for this update: 3.269\n",
      "New Record!\n",
      "Average loss for this update: 9.144\n",
      "No Improvement.\n",
      "Average loss for this update: 5.526\n",
      "No Improvement.\n",
      "step:5 batch_loss:5.613393306732178\n",
      "Epoch   2/100 Batch    1/4 - Loss:  0.281, Seconds: 3.85\n",
      "Average loss for this update: 5.613\n",
      "No Improvement.\n",
      "Average loss for this update: 2.443\n",
      "New Record!\n",
      "Average loss for this update: 3.351\n",
      "No Improvement.\n",
      "Average loss for this update: 3.849\n",
      "No Improvement.\n",
      "step:9 batch_loss:3.509451150894165\n",
      "Epoch   3/100 Batch    1/4 - Loss:  0.175, Seconds: 2.13\n",
      "Average loss for this update: 3.509\n",
      "No Improvement.\n",
      "Average loss for this update: 1.846\n",
      "New Record!\n",
      "Average loss for this update: 3.143\n",
      "No Improvement.\n",
      "Average loss for this update: 2.544\n",
      "No Improvement.\n",
      "step:13 batch_loss:2.495534658432007\n",
      "Epoch   4/100 Batch    1/4 - Loss:  0.125, Seconds: 2.19\n",
      "Average loss for this update: 2.496\n",
      "No Improvement.\n",
      "Average loss for this update: 2.066\n",
      "No Improvement.\n",
      "Average loss for this update: 2.336\n",
      "No Improvement.\n",
      "Average loss for this update: 1.919\n",
      "No Improvement.\n",
      "step:17 batch_loss:2.1400203704833984\n",
      "Epoch   5/100 Batch    1/4 - Loss:  0.107, Seconds: 2.13\n",
      "Average loss for this update: 2.14\n",
      "No Improvement.\n",
      "Average loss for this update: 1.812\n",
      "New Record!\n",
      "Average loss for this update: 1.737\n",
      "New Record!\n",
      "Average loss for this update: 1.674\n",
      "New Record!\n",
      "step:21 batch_loss:1.855550765991211\n",
      "Epoch   6/100 Batch    1/4 - Loss:  0.093, Seconds: 2.07\n",
      "Average loss for this update: 1.856\n",
      "No Improvement.\n",
      "Average loss for this update: 1.59\n",
      "New Record!\n",
      "Average loss for this update: 1.382\n",
      "New Record!\n",
      "Average loss for this update: 1.7\n",
      "No Improvement.\n",
      "step:25 batch_loss:1.5833810567855835\n",
      "Epoch   7/100 Batch    1/4 - Loss:  0.079, Seconds: 2.07\n",
      "Average loss for this update: 1.583\n",
      "No Improvement.\n",
      "Average loss for this update: 1.334\n",
      "New Record!\n",
      "Average loss for this update: 1.682\n",
      "No Improvement.\n",
      "Average loss for this update: 1.257\n",
      "New Record!\n",
      "step:29 batch_loss:1.3901556730270386\n",
      "Epoch   8/100 Batch    1/4 - Loss:  0.070, Seconds: 2.09\n",
      "Average loss for this update: 1.39\n",
      "No Improvement.\n",
      "Average loss for this update: 1.491\n",
      "No Improvement.\n",
      "Average loss for this update: 1.415\n",
      "No Improvement.\n",
      "Average loss for this update: 1.094\n",
      "New Record!\n",
      "step:33 batch_loss:1.6880102157592773\n",
      "Epoch   9/100 Batch    1/4 - Loss:  0.084, Seconds: 6.08\n",
      "Average loss for this update: 1.688\n",
      "No Improvement.\n",
      "Average loss for this update: 1.259\n",
      "No Improvement.\n",
      "Average loss for this update: 2.0\n",
      "No Improvement.\n",
      "Average loss for this update: 1.687\n",
      "No Improvement.\n",
      "step:37 batch_loss:1.3658918142318726\n",
      "Epoch  10/100 Batch    1/4 - Loss:  0.068, Seconds: 2.05\n",
      "Average loss for this update: 1.366\n",
      "No Improvement.\n",
      "Average loss for this update: 1.332\n",
      "No Improvement.\n",
      "Average loss for this update: 1.332\n",
      "No Improvement.\n",
      "Average loss for this update: 2.039\n",
      "No Improvement.\n",
      "step:41 batch_loss:1.1704832315444946\n",
      "Epoch  11/100 Batch    1/4 - Loss:  0.059, Seconds: 3.77\n",
      "Average loss for this update: 1.17\n",
      "No Improvement.\n",
      "Average loss for this update: 2.783\n",
      "No Improvement.\n",
      "Average loss for this update: 1.033\n",
      "New Record!\n",
      "Average loss for this update: 1.669\n",
      "No Improvement.\n",
      "step:45 batch_loss:1.4080564975738525\n",
      "Epoch  12/100 Batch    1/4 - Loss:  0.070, Seconds: 2.01\n",
      "Average loss for this update: 1.408\n",
      "No Improvement.\n",
      "Average loss for this update: 1.717\n",
      "No Improvement.\n",
      "Average loss for this update: 1.44\n",
      "No Improvement.\n",
      "Average loss for this update: 1.128\n",
      "No Improvement.\n",
      "step:49 batch_loss:1.5972355604171753\n",
      "Epoch  13/100 Batch    1/4 - Loss:  0.080, Seconds: 6.12\n",
      "Average loss for this update: 1.597\n",
      "No Improvement.\n",
      "Average loss for this update: 1.266\n",
      "No Improvement.\n",
      "Average loss for this update: 1.489\n",
      "No Improvement.\n",
      "Average loss for this update: 1.172\n",
      "No Improvement.\n",
      "step:53 batch_loss:1.190312147140503\n",
      "Epoch  14/100 Batch    1/4 - Loss:  0.060, Seconds: 3.49\n",
      "Average loss for this update: 1.19\n",
      "No Improvement.\n",
      "Average loss for this update: 0.973\n",
      "New Record!\n",
      "Average loss for this update: 1.223\n",
      "No Improvement.\n",
      "Average loss for this update: 0.908\n",
      "New Record!\n",
      "step:57 batch_loss:0.7515445351600647\n",
      "Epoch  15/100 Batch    1/4 - Loss:  0.038, Seconds: 2.43\n",
      "Average loss for this update: 0.752\n",
      "New Record!\n",
      "Average loss for this update: 1.321\n",
      "No Improvement.\n",
      "Average loss for this update: 0.735\n",
      "New Record!\n",
      "Average loss for this update: 0.711\n",
      "New Record!\n",
      "step:61 batch_loss:0.6693019866943359\n",
      "Epoch  16/100 Batch    1/4 - Loss:  0.033, Seconds: 2.21\n",
      "Average loss for this update: 0.669\n",
      "New Record!\n",
      "Average loss for this update: 1.08\n",
      "No Improvement.\n",
      "Average loss for this update: 0.758\n",
      "No Improvement.\n",
      "Average loss for this update: 0.448\n",
      "New Record!\n",
      "step:65 batch_loss:0.9368852376937866\n",
      "Epoch  17/100 Batch    1/4 - Loss:  0.047, Seconds: 2.17\n",
      "Average loss for this update: 0.937\n",
      "No Improvement.\n",
      "Average loss for this update: 0.919\n",
      "No Improvement.\n",
      "Average loss for this update: 1.058\n",
      "No Improvement.\n",
      "Average loss for this update: 0.583\n",
      "No Improvement.\n",
      "step:69 batch_loss:0.6338948607444763\n",
      "Epoch  18/100 Batch    1/4 - Loss:  0.032, Seconds: 2.13\n",
      "Average loss for this update: 0.634\n",
      "No Improvement.\n",
      "Average loss for this update: 1.429\n",
      "No Improvement.\n",
      "Average loss for this update: 0.799\n",
      "No Improvement.\n",
      "Average loss for this update: 0.294\n",
      "New Record!\n",
      "step:73 batch_loss:0.42633089423179626\n",
      "Epoch  19/100 Batch    1/4 - Loss:  0.021, Seconds: 2.57\n",
      "Average loss for this update: 0.426\n",
      "No Improvement.\n",
      "Average loss for this update: 0.997\n",
      "No Improvement.\n",
      "Average loss for this update: 1.244\n",
      "No Improvement.\n",
      "Average loss for this update: 0.862\n",
      "No Improvement.\n",
      "step:77 batch_loss:0.5320743918418884\n",
      "Epoch  20/100 Batch    1/4 - Loss:  0.027, Seconds: 1.84\n",
      "Average loss for this update: 0.532\n",
      "No Improvement.\n",
      "Average loss for this update: 1.098\n",
      "No Improvement.\n",
      "Average loss for this update: 0.714\n",
      "No Improvement.\n",
      "Average loss for this update: 0.862\n",
      "No Improvement.\n",
      "step:81 batch_loss:0.8756365776062012\n",
      "Epoch  21/100 Batch    1/4 - Loss:  0.044, Seconds: 1.97\n",
      "Average loss for this update: 0.876\n",
      "No Improvement.\n",
      "Average loss for this update: 1.103\n",
      "No Improvement.\n",
      "Average loss for this update: 0.785\n",
      "No Improvement.\n",
      "Average loss for this update: 0.552\n",
      "No Improvement.\n",
      "step:85 batch_loss:0.23679444193840027\n",
      "Epoch  22/100 Batch    1/4 - Loss:  0.012, Seconds: 2.21\n",
      "Average loss for this update: 0.237\n",
      "New Record!\n",
      "Average loss for this update: 0.802\n",
      "No Improvement.\n",
      "Average loss for this update: 0.635\n",
      "No Improvement.\n",
      "Average loss for this update: 0.208\n",
      "New Record!\n",
      "step:89 batch_loss:0.22120973467826843\n",
      "Epoch  23/100 Batch    1/4 - Loss:  0.011, Seconds: 2.13\n",
      "Average loss for this update: 0.221\n",
      "No Improvement.\n",
      "Average loss for this update: 0.589\n",
      "No Improvement.\n",
      "Average loss for this update: 0.721\n",
      "No Improvement.\n",
      "Average loss for this update: 0.265\n",
      "No Improvement.\n",
      "step:93 batch_loss:0.609599232673645\n",
      "Epoch  24/100 Batch    1/4 - Loss:  0.030, Seconds: 2.15\n",
      "Average loss for this update: 0.61\n",
      "No Improvement.\n",
      "Average loss for this update: 0.816\n",
      "No Improvement.\n",
      "Average loss for this update: 0.618\n",
      "No Improvement.\n",
      "Average loss for this update: 0.1\n",
      "New Record!\n",
      "step:97 batch_loss:0.1523665189743042\n",
      "Epoch  25/100 Batch    1/4 - Loss:  0.008, Seconds: 2.17\n",
      "Average loss for this update: 0.152\n",
      "No Improvement.\n",
      "Average loss for this update: 0.55\n",
      "No Improvement.\n",
      "Average loss for this update: 0.314\n",
      "No Improvement.\n",
      "Average loss for this update: 0.062\n",
      "New Record!\n",
      "step:101 batch_loss:0.2219613641500473\n",
      "Epoch  26/100 Batch    1/4 - Loss:  0.011, Seconds: 2.31\n",
      "Average loss for this update: 0.222\n",
      "No Improvement.\n",
      "Average loss for this update: 0.516\n",
      "No Improvement.\n",
      "Average loss for this update: 0.407\n",
      "No Improvement.\n",
      "Average loss for this update: 0.025\n",
      "New Record!\n",
      "step:105 batch_loss:0.09341108798980713\n",
      "Epoch  27/100 Batch    1/4 - Loss:  0.005, Seconds: 2.33\n",
      "Average loss for this update: 0.093\n",
      "No Improvement.\n",
      "Average loss for this update: 0.556\n",
      "No Improvement.\n",
      "Average loss for this update: 0.479\n",
      "No Improvement.\n",
      "Average loss for this update: 0.017\n",
      "New Record!\n",
      "step:109 batch_loss:0.033169787377119064\n",
      "Epoch  28/100 Batch    1/4 - Loss:  0.002, Seconds: 2.95\n",
      "Average loss for this update: 0.033\n",
      "No Improvement.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss for this update: 0.39\n",
      "No Improvement.\n",
      "Average loss for this update: 0.304\n",
      "No Improvement.\n",
      "Average loss for this update: 0.052\n",
      "No Improvement.\n",
      "step:113 batch_loss:0.012380048632621765\n",
      "Epoch  29/100 Batch    1/4 - Loss:  0.001, Seconds: 1.99\n",
      "Average loss for this update: 0.012\n",
      "New Record!\n",
      "Average loss for this update: 0.287\n",
      "No Improvement.\n",
      "Average loss for this update: 0.184\n",
      "No Improvement.\n",
      "Average loss for this update: 0.011\n",
      "New Record!\n",
      "step:117 batch_loss:0.012049187906086445\n",
      "Epoch  30/100 Batch    1/4 - Loss:  0.001, Seconds: 2.35\n",
      "Average loss for this update: 0.012\n",
      "No Improvement.\n",
      "Average loss for this update: 0.298\n",
      "No Improvement.\n",
      "Average loss for this update: 0.1\n",
      "No Improvement.\n",
      "Average loss for this update: 0.016\n",
      "No Improvement.\n",
      "step:121 batch_loss:0.01628534495830536\n",
      "Epoch  31/100 Batch    1/4 - Loss:  0.001, Seconds: 2.05\n",
      "Average loss for this update: 0.016\n",
      "No Improvement.\n",
      "Average loss for this update: 0.267\n",
      "No Improvement.\n",
      "Average loss for this update: 0.073\n",
      "No Improvement.\n",
      "Average loss for this update: 0.009\n",
      "New Record!\n",
      "step:125 batch_loss:0.009571650065481663\n",
      "Epoch  32/100 Batch    1/4 - Loss:  0.000, Seconds: 2.15\n",
      "Average loss for this update: 0.01\n",
      "No Improvement.\n",
      "Average loss for this update: 0.226\n",
      "No Improvement.\n",
      "Average loss for this update: 0.068\n",
      "No Improvement.\n",
      "Average loss for this update: 0.011\n",
      "No Improvement.\n",
      "step:129 batch_loss:0.011014453135430813\n",
      "Epoch  33/100 Batch    1/4 - Loss:  0.001, Seconds: 5.51\n",
      "Average loss for this update: 0.011\n",
      "No Improvement.\n",
      "Average loss for this update: 0.411\n",
      "No Improvement.\n",
      "Average loss for this update: 0.034\n",
      "No Improvement.\n",
      "Average loss for this update: 0.009\n",
      "New Record!\n",
      "step:133 batch_loss:0.007042015437036753\n",
      "Epoch  34/100 Batch    1/4 - Loss:  0.000, Seconds: 2.19\n",
      "Average loss for this update: 0.007\n",
      "New Record!\n",
      "Average loss for this update: 0.264\n",
      "No Improvement.\n",
      "Average loss for this update: 0.054\n",
      "No Improvement.\n",
      "Average loss for this update: 0.007\n",
      "New Record!\n",
      "step:137 batch_loss:0.02234116569161415\n",
      "Epoch  35/100 Batch    1/4 - Loss:  0.001, Seconds: 3.13\n",
      "Average loss for this update: 0.022\n",
      "No Improvement.\n",
      "Average loss for this update: 0.192\n",
      "No Improvement.\n",
      "Average loss for this update: 0.063\n",
      "No Improvement.\n",
      "Average loss for this update: 0.005\n",
      "New Record!\n",
      "step:141 batch_loss:0.006411482114344835\n",
      "Epoch  36/100 Batch    1/4 - Loss:  0.000, Seconds: 3.87\n",
      "Average loss for this update: 0.006\n",
      "No Improvement.\n",
      "Average loss for this update: 0.286\n",
      "No Improvement.\n",
      "Average loss for this update: 0.03\n",
      "No Improvement.\n",
      "Average loss for this update: 0.008\n",
      "No Improvement.\n",
      "step:145 batch_loss:0.007573106326162815\n",
      "Epoch  37/100 Batch    1/4 - Loss:  0.000, Seconds: 2.71\n",
      "Average loss for this update: 0.008\n",
      "No Improvement.\n",
      "Average loss for this update: 0.223\n",
      "No Improvement.\n",
      "Average loss for this update: 0.026\n",
      "No Improvement.\n",
      "Average loss for this update: 0.01\n",
      "No Improvement.\n",
      "step:149 batch_loss:0.005464314483106136\n",
      "Epoch  38/100 Batch    1/4 - Loss:  0.000, Seconds: 2.11\n",
      "Average loss for this update: 0.005\n",
      "No Improvement.\n",
      "Average loss for this update: 0.163\n",
      "No Improvement.\n",
      "Average loss for this update: 0.015\n",
      "No Improvement.\n",
      "Average loss for this update: 0.006\n",
      "No Improvement.\n",
      "step:153 batch_loss:0.004790326114743948\n",
      "Epoch  39/100 Batch    1/4 - Loss:  0.000, Seconds: 1.89\n",
      "Average loss for this update: 0.005\n",
      "No Improvement.\n",
      "Average loss for this update: 0.134\n",
      "No Improvement.\n",
      "Average loss for this update: 0.01\n",
      "No Improvement.\n",
      "Average loss for this update: 0.004\n",
      "New Record!\n",
      "step:157 batch_loss:0.004017314407974482\n",
      "Epoch  40/100 Batch    1/4 - Loss:  0.000, Seconds: 2.03\n",
      "Average loss for this update: 0.004\n",
      "New Record!\n",
      "Average loss for this update: 0.109\n",
      "No Improvement.\n",
      "Average loss for this update: 0.008\n",
      "No Improvement.\n",
      "Average loss for this update: 0.003\n",
      "New Record!\n",
      "step:161 batch_loss:0.0035888345446437597\n",
      "Epoch  41/100 Batch    1/4 - Loss:  0.000, Seconds: 2.69\n",
      "Average loss for this update: 0.004\n",
      "No Improvement.\n",
      "Average loss for this update: 0.084\n",
      "No Improvement.\n",
      "Average loss for this update: 0.007\n",
      "No Improvement.\n",
      "Average loss for this update: 0.003\n",
      "New Record!\n",
      "step:165 batch_loss:0.0031261418480426073\n",
      "Epoch  42/100 Batch    1/4 - Loss:  0.000, Seconds: 2.21\n",
      "Average loss for this update: 0.003\n",
      "No Improvement.\n",
      "Average loss for this update: 0.074\n",
      "No Improvement.\n",
      "Average loss for this update: 0.006\n",
      "No Improvement.\n",
      "Average loss for this update: 0.003\n",
      "No Improvement.\n",
      "step:169 batch_loss:0.002809469820931554\n",
      "Epoch  43/100 Batch    1/4 - Loss:  0.000, Seconds: 2.05\n",
      "Average loss for this update: 0.003\n",
      "No Improvement.\n",
      "Average loss for this update: 0.061\n",
      "No Improvement.\n",
      "Average loss for this update: 0.004\n",
      "No Improvement.\n",
      "Average loss for this update: 0.003\n",
      "New Record!\n",
      "step:173 batch_loss:0.0023875252809375525\n",
      "Epoch  44/100 Batch    1/4 - Loss:  0.000, Seconds: 2.07\n",
      "Average loss for this update: 0.002\n",
      "New Record!\n",
      "Average loss for this update: 0.048\n",
      "No Improvement.\n",
      "Average loss for this update: 0.005\n",
      "No Improvement.\n",
      "Average loss for this update: 0.003\n",
      "No Improvement.\n",
      "step:177 batch_loss:0.0032561507541686296\n",
      "Epoch  45/100 Batch    1/4 - Loss:  0.000, Seconds: 1.76\n",
      "Average loss for this update: 0.003\n",
      "No Improvement.\n",
      "Average loss for this update: 0.036\n",
      "No Improvement.\n",
      "Average loss for this update: 0.004\n",
      "No Improvement.\n",
      "Average loss for this update: 0.002\n",
      "No Improvement.\n",
      "step:181 batch_loss:0.002143635181710124\n",
      "Epoch  46/100 Batch    1/4 - Loss:  0.000, Seconds: 1.91\n",
      "Average loss for this update: 0.002\n",
      "New Record!\n",
      "Average loss for this update: 0.027\n",
      "No Improvement.\n",
      "Average loss for this update: 0.004\n",
      "No Improvement.\n",
      "Average loss for this update: 0.002\n",
      "New Record!\n",
      "step:185 batch_loss:0.0023244176991283894\n",
      "Epoch  47/100 Batch    1/4 - Loss:  0.000, Seconds: 2.35\n",
      "Average loss for this update: 0.002\n",
      "No Improvement.\n",
      "Average loss for this update: 0.02\n",
      "No Improvement.\n",
      "Average loss for this update: 0.004\n",
      "No Improvement.\n",
      "Average loss for this update: 0.002\n",
      "New Record!\n",
      "step:189 batch_loss:0.0019125157268717885\n",
      "Epoch  48/100 Batch    1/4 - Loss:  0.000, Seconds: 2.31\n",
      "Average loss for this update: 0.002\n",
      "No Improvement.\n",
      "Average loss for this update: 0.02\n",
      "No Improvement.\n",
      "Average loss for this update: 0.003\n",
      "No Improvement.\n",
      "Average loss for this update: 0.001\n",
      "New Record!\n",
      "step:193 batch_loss:0.0018876120448112488\n",
      "Epoch  49/100 Batch    1/4 - Loss:  0.000, Seconds: 2.31\n",
      "Average loss for this update: 0.002\n",
      "No Improvement.\n",
      "Average loss for this update: 0.027\n",
      "No Improvement.\n",
      "Average loss for this update: 0.003\n",
      "No Improvement.\n",
      "Average loss for this update: 0.002\n",
      "No Improvement.\n",
      "step:197 batch_loss:0.001972345868125558\n",
      "Epoch  50/100 Batch    1/4 - Loss:  0.000, Seconds: 1.89\n",
      "Average loss for this update: 0.002\n",
      "No Improvement.\n",
      "Average loss for this update: 0.061\n",
      "No Improvement.\n",
      "Average loss for this update: 0.003\n",
      "No Improvement.\n",
      "Average loss for this update: 0.001\n",
      "No Improvement.\n",
      "step:201 batch_loss:0.0016614228952676058\n",
      "Epoch  51/100 Batch    1/4 - Loss:  0.000, Seconds: 2.09\n",
      "Average loss for this update: 0.002\n",
      "No Improvement.\n",
      "Average loss for this update: 0.117\n",
      "No Improvement.\n",
      "Average loss for this update: 0.003\n",
      "No Improvement.\n",
      "Average loss for this update: 0.002\n",
      "No Improvement.\n",
      "step:205 batch_loss:0.0022064209915697575\n",
      "Epoch  52/100 Batch    1/4 - Loss:  0.000, Seconds: 1.91\n",
      "Average loss for this update: 0.002\n",
      "No Improvement.\n",
      "Average loss for this update: 0.099\n",
      "No Improvement.\n",
      "Average loss for this update: 0.006\n",
      "No Improvement.\n",
      "Average loss for this update: 0.004\n",
      "No Improvement.\n",
      "step:209 batch_loss:0.0020198686979711056\n",
      "Epoch  53/100 Batch    1/4 - Loss:  0.000, Seconds: 2.19\n",
      "Average loss for this update: 0.002\n",
      "No Improvement.\n",
      "Average loss for this update: 0.06\n",
      "No Improvement.\n",
      "Average loss for this update: 0.003\n",
      "No Improvement.\n",
      "Average loss for this update: 0.003\n",
      "No Improvement.\n",
      "Stopping Training.\n"
     ]
    }
   ],
   "source": [
    "# Train the Model\n",
    "learning_rate_decay = 0.95\n",
    "min_learning_rate = 0.0005\n",
    "display_step = 20 # Check training loss after every 20 batches\n",
    "stop_early = 0 \n",
    "stop = 20 #3 # If the update loss does not decrease in 3 consecutive update checks, stop training\n",
    "per_epoch = 3 # Make 3 update checks per epoch\n",
    "update_check = max(1, (len(sorted_texts_short)//batch_size//per_epoch)-1)\n",
    "\n",
    "update_loss = 0 \n",
    "batch_loss = 0\n",
    "summary_update_loss = [] # Record the update losses for saving improvements in the model\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "if not os.path.exists('checkpoints'):\n",
    "    os.makedirs('checkpoints')\n",
    "\n",
    "if not os.path.exists('log'):\n",
    "    os.makedirs('log')\n",
    "\n",
    "checkpoint = \"checkpoints/best_model.ckpt\"  #300k sentence\n",
    "\n",
    "log_dir = \"log\"\n",
    "\n",
    "writer = SummaryWriter(log_dir=os.path.join(log_dir))\n",
    "\n",
    "with tf.Session(graph=train_graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # If we want to continue training a previous session\n",
    "    # loader = tf.train.import_meta_graph(checkpoint + '.meta')\n",
    "    # loader.restore(sess, checkpoint)\n",
    "    #sess.run(tf.local_variables_initializer())\n",
    "    step = 0\n",
    "    for epoch_i in range(1, epochs+1):\n",
    "        update_loss = 0\n",
    "        batch_loss = 0\n",
    "\n",
    "        for batch_i, (summaries_batch, texts_batch, summaries_lengths, texts_lengths) in enumerate(\n",
    "                get_batches(sorted_summaries_short, sorted_texts_short, batch_size)):\n",
    "            \n",
    "            start_time = time.time()\n",
    "            _, loss = sess.run(\n",
    "                [train_op, cost],\n",
    "                {input_data: texts_batch,\n",
    "                 targets: summaries_batch,\n",
    "                 lr: learning_rate,\n",
    "                 summary_length: summaries_lengths,\n",
    "                 text_length: texts_lengths,\n",
    "                 keep_prob: keep_probability})\n",
    "\n",
    "            batch_loss += loss\n",
    "            update_loss += loss\n",
    "            end_time = time.time()\n",
    "            batch_time = end_time - start_time\n",
    "            step += 1\n",
    "            if batch_i % display_step == 0 and batch_i + 1> 0:\n",
    "                print(\"step:\"+str(step), 'batch_loss:'+ str(batch_loss))\n",
    "                print('Epoch {:>3}/{} Batch {:>4}/{} - Loss: {:>6.3f}, Seconds: {:>4.2f}'\n",
    "                      .format(epoch_i,\n",
    "                              epochs, \n",
    "                              batch_i + 1, \n",
    "                              len(sorted_texts_short) // batch_size, \n",
    "                              batch_loss / display_step, \n",
    "                              batch_time*display_step))\n",
    "                writer.add_scalar('Train/Loss', batch_loss, step)\n",
    "                batch_loss = 0\n",
    "                #saver = tf.train.Saver() \n",
    "                #saver.save(sess, checkpoint)\n",
    "                \n",
    "            if batch_i % update_check == 0 and batch_i + 1 > 0:\n",
    "                print(\"Average loss for this update:\", round(update_loss/update_check,3))\n",
    "                summary_update_loss.append(update_loss)\n",
    "                \n",
    "              \n",
    "                  \n",
    "                # If the update loss is at a new minimum, save the model\n",
    "                if update_loss <= min(summary_update_loss):\n",
    "                    print('New Record!') \n",
    "                    stop_early = 0\n",
    "                    saver = tf.train.Saver() \n",
    "                    saver.save(sess, checkpoint)\n",
    "\n",
    "                else:\n",
    "                    print(\"No Improvement.\")\n",
    "                    stop_early += 1\n",
    "                    if stop_early == stop:\n",
    "                        break\n",
    "                update_loss = 0\n",
    "            \n",
    "                    \n",
    "        # Reduce learning rate, but not below its minimum value\n",
    "        learning_rate *= learning_rate_decay\n",
    "        if learning_rate < min_learning_rate:\n",
    "            learning_rate = min_learning_rate\n",
    "        \n",
    "        if stop_early == stop:\n",
    "            print(\"Stopping Training.\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\anaconda3\\envs\\sum\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/best_model.ckpt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['input',\n",
       " 'targets',\n",
       " 'learning_rate',\n",
       " 'keep_prob',\n",
       " 'summary_length',\n",
       " 'Const',\n",
       " 'max_dec_len',\n",
       " 'text_length',\n",
       " 'ReverseV2/axis',\n",
       " 'ReverseV2',\n",
       " 'embedding_lookup/params_0',\n",
       " 'embedding_lookup/axis',\n",
       " 'embedding_lookup',\n",
       " 'embedding_lookup/Identity',\n",
       " 'encoder_0/DropoutWrapperInit/Const',\n",
       " 'encoder_0/DropoutWrapperInit/Const_1',\n",
       " 'encoder_0/DropoutWrapperInit_1/Const',\n",
       " 'encoder_0/DropoutWrapperInit_1/Const_1',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/Rank',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/range/start',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/range/delta',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/range',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/concat/values_0',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/concat/axis',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/concat',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/transpose',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/sequence_length',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/Shape',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/strided_slice/stack',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/strided_slice/stack_1',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/strided_slice/stack_2',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/strided_slice',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/ExpandDims/dim',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/ExpandDims',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/Const',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/concat/axis',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/concat',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/zeros/Const',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/zeros',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/ExpandDims_1/dim',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/ExpandDims_1',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/Const_1',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/ExpandDims_2/dim',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/ExpandDims_2',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/Const_2',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/concat_1/axis',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/concat_1',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/zeros_1/Const',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/zeros_1',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/ExpandDims_3/dim',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/ExpandDims_3',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/Const_3',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/Shape_1',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/stack',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/Equal',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/Const',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/All',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/Assert/Const',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/Assert/Const_1',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/Assert/Assert/data_0',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/Assert/Assert/data_2',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/Assert/Assert',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/CheckSeqLen',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/Shape_2',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/strided_slice_1/stack',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/strided_slice_1/stack_1',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/strided_slice_1/stack_2',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/strided_slice_1',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/Shape_3',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/strided_slice_2/stack',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/strided_slice_2/stack_1',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/strided_slice_2/stack_2',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/strided_slice_2',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/ExpandDims/dim',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/ExpandDims',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/Const_1',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/concat_1/axis',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/concat_1',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/zeros/Const',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/zeros',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/Const_2',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/Min',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/Const_3',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/Max',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/time',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/TensorArray',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/TensorArray_1',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/TensorArrayUnstack/Shape',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/TensorArrayUnstack/strided_slice/stack',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/TensorArrayUnstack/strided_slice/stack_1',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/TensorArrayUnstack/strided_slice/stack_2',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/TensorArrayUnstack/strided_slice',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/TensorArrayUnstack/range/start',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/TensorArrayUnstack/range/delta',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/TensorArrayUnstack/range',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/Maximum/x',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/Maximum',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/Minimum',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/iteration_counter',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/Enter',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/Enter_1',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/Enter_2',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/Enter_3',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/Enter_4',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/Merge',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/Merge_1',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/Merge_2',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/Merge_3',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/Merge_4',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/Less/Enter',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/Less',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/Less_1/Enter',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/Less_1',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/LogicalAnd',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/LoopCond',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/Switch',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/Switch_1',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/Switch_2',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/Switch_3',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/Switch_4',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/Identity',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/Identity_1',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/Identity_2',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/Identity_3',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/Identity_4',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/add/y',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/add',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/TensorArrayReadV3/Enter',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/TensorArrayReadV3/Enter_1',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/TensorArrayReadV3',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/GreaterEqual/Enter',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/GreaterEqual',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/sub/x',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/sub/Enter',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/sub',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/dropout/Shape',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/dropout/random_uniform/min',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/dropout/random_uniform/max',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/dropout/random_uniform/RandomUniform',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/dropout/random_uniform/sub',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/dropout/random_uniform/mul',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/dropout/random_uniform',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/dropout/sub/x',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/dropout/sub',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/dropout/truediv/x',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/dropout/truediv',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/dropout/GreaterEqual',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/dropout/mul',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/dropout/Cast',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/dropout/mul_1',\n",
       " 'encoder_0/bidirectional_rnn/fw/lstm_cell/kernel/Initializer/random_uniform/shape',\n",
       " 'encoder_0/bidirectional_rnn/fw/lstm_cell/kernel/Initializer/random_uniform/min',\n",
       " 'encoder_0/bidirectional_rnn/fw/lstm_cell/kernel/Initializer/random_uniform/max',\n",
       " 'encoder_0/bidirectional_rnn/fw/lstm_cell/kernel/Initializer/random_uniform/RandomUniform',\n",
       " 'encoder_0/bidirectional_rnn/fw/lstm_cell/kernel/Initializer/random_uniform/sub',\n",
       " 'encoder_0/bidirectional_rnn/fw/lstm_cell/kernel/Initializer/random_uniform/mul',\n",
       " 'encoder_0/bidirectional_rnn/fw/lstm_cell/kernel/Initializer/random_uniform',\n",
       " 'encoder_0/bidirectional_rnn/fw/lstm_cell/kernel',\n",
       " 'encoder_0/bidirectional_rnn/fw/lstm_cell/kernel/Assign',\n",
       " 'encoder_0/bidirectional_rnn/fw/lstm_cell/kernel/read',\n",
       " 'encoder_0/bidirectional_rnn/fw/lstm_cell/bias/Initializer/zeros/shape_as_tensor',\n",
       " 'encoder_0/bidirectional_rnn/fw/lstm_cell/bias/Initializer/zeros/Const',\n",
       " 'encoder_0/bidirectional_rnn/fw/lstm_cell/bias/Initializer/zeros',\n",
       " 'encoder_0/bidirectional_rnn/fw/lstm_cell/bias',\n",
       " 'encoder_0/bidirectional_rnn/fw/lstm_cell/bias/Assign',\n",
       " 'encoder_0/bidirectional_rnn/fw/lstm_cell/bias/read',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/lstm_cell/concat/axis',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/lstm_cell/concat',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/lstm_cell/MatMul/Enter',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/lstm_cell/MatMul',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/lstm_cell/BiasAdd/Enter',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/lstm_cell/BiasAdd',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/lstm_cell/Const',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/lstm_cell/split/split_dim',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/lstm_cell/split',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/lstm_cell/add/y',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/lstm_cell/add',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/lstm_cell/Sigmoid',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/lstm_cell/mul',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/lstm_cell/Sigmoid_1',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/lstm_cell/Tanh',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/lstm_cell/mul_1',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/lstm_cell/add_1',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/lstm_cell/Sigmoid_2',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/lstm_cell/Tanh_1',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/lstm_cell/mul_2',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/Select/Enter',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/Select',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/Select_1',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/Select_2',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/TensorArrayWrite/TensorArrayWriteV3/Enter',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/TensorArrayWrite/TensorArrayWriteV3',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/add_1/y',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/add_1',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/NextIteration',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/NextIteration_1',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/NextIteration_2',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/NextIteration_3',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/NextIteration_4',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/Exit',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/Exit_1',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/Exit_2',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/Exit_3',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/Exit_4',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/TensorArrayStack/TensorArraySizeV3',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/TensorArrayStack/range/start',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/TensorArrayStack/range/delta',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/TensorArrayStack/range',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/TensorArrayStack/TensorArrayGatherV3',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/Const_4',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/Rank_1',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/range_1/start',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/range_1/delta',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/range_1',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/concat_2/values_0',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/concat_2/axis',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/concat_2',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/transpose_1',\n",
       " 'encoder_0/bidirectional_rnn/bw/ReverseSequence',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/Rank',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/range/start',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/range/delta',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/range',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/concat/values_0',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/concat/axis',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/concat',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/transpose',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/sequence_length',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/Shape',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/strided_slice/stack',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/strided_slice/stack_1',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/strided_slice/stack_2',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/strided_slice',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/ExpandDims/dim',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/ExpandDims',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/Const',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/concat/axis',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/concat',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/zeros/Const',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/zeros',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/ExpandDims_1/dim',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/ExpandDims_1',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/Const_1',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/ExpandDims_2/dim',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/ExpandDims_2',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/Const_2',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/concat_1/axis',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/concat_1',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/zeros_1/Const',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/zeros_1',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/ExpandDims_3/dim',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/ExpandDims_3',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/Const_3',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/Shape_1',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/stack',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/Equal',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/Const',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/All',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/Assert/Const',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/Assert/Const_1',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/Assert/Assert/data_0',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/Assert/Assert/data_2',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/Assert/Assert',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/CheckSeqLen',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/Shape_2',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/strided_slice_1/stack',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/strided_slice_1/stack_1',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/strided_slice_1/stack_2',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/strided_slice_1',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/Shape_3',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/strided_slice_2/stack',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/strided_slice_2/stack_1',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/strided_slice_2/stack_2',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/strided_slice_2',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/ExpandDims/dim',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/ExpandDims',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/Const_1',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/concat_1/axis',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/concat_1',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/zeros/Const',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/zeros',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/Const_2',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/Min',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/Const_3',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/Max',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/time',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/TensorArray',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/TensorArray_1',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/TensorArrayUnstack/Shape',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/TensorArrayUnstack/strided_slice/stack',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/TensorArrayUnstack/strided_slice/stack_1',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/TensorArrayUnstack/strided_slice/stack_2',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/TensorArrayUnstack/strided_slice',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/TensorArrayUnstack/range/start',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/TensorArrayUnstack/range/delta',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/TensorArrayUnstack/range',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/Maximum/x',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/Maximum',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/Minimum',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/iteration_counter',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/Enter',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/Enter_1',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/Enter_2',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/Enter_3',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/Enter_4',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/Merge',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/Merge_1',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/Merge_2',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/Merge_3',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/Merge_4',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/Less/Enter',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/Less',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/Less_1/Enter',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/Less_1',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/LogicalAnd',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/LoopCond',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/Switch',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/Switch_1',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/Switch_2',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/Switch_3',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/Switch_4',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/Identity',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/Identity_1',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/Identity_2',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/Identity_3',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/Identity_4',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/add/y',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/add',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/TensorArrayReadV3/Enter',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/TensorArrayReadV3/Enter_1',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/TensorArrayReadV3',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/GreaterEqual/Enter',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/GreaterEqual',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/sub/x',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/sub/Enter',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/sub',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/dropout/Shape',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/dropout/random_uniform/min',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/dropout/random_uniform/max',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/dropout/random_uniform/RandomUniform',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/dropout/random_uniform/sub',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/dropout/random_uniform/mul',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/dropout/random_uniform',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/dropout/sub/x',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/dropout/sub',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/dropout/truediv/x',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/dropout/truediv',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/dropout/GreaterEqual',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/dropout/mul',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/dropout/Cast',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/dropout/mul_1',\n",
       " 'encoder_0/bidirectional_rnn/bw/lstm_cell/kernel/Initializer/random_uniform/shape',\n",
       " 'encoder_0/bidirectional_rnn/bw/lstm_cell/kernel/Initializer/random_uniform/min',\n",
       " 'encoder_0/bidirectional_rnn/bw/lstm_cell/kernel/Initializer/random_uniform/max',\n",
       " 'encoder_0/bidirectional_rnn/bw/lstm_cell/kernel/Initializer/random_uniform/RandomUniform',\n",
       " 'encoder_0/bidirectional_rnn/bw/lstm_cell/kernel/Initializer/random_uniform/sub',\n",
       " 'encoder_0/bidirectional_rnn/bw/lstm_cell/kernel/Initializer/random_uniform/mul',\n",
       " 'encoder_0/bidirectional_rnn/bw/lstm_cell/kernel/Initializer/random_uniform',\n",
       " 'encoder_0/bidirectional_rnn/bw/lstm_cell/kernel',\n",
       " 'encoder_0/bidirectional_rnn/bw/lstm_cell/kernel/Assign',\n",
       " 'encoder_0/bidirectional_rnn/bw/lstm_cell/kernel/read',\n",
       " 'encoder_0/bidirectional_rnn/bw/lstm_cell/bias/Initializer/zeros/shape_as_tensor',\n",
       " 'encoder_0/bidirectional_rnn/bw/lstm_cell/bias/Initializer/zeros/Const',\n",
       " 'encoder_0/bidirectional_rnn/bw/lstm_cell/bias/Initializer/zeros',\n",
       " 'encoder_0/bidirectional_rnn/bw/lstm_cell/bias',\n",
       " 'encoder_0/bidirectional_rnn/bw/lstm_cell/bias/Assign',\n",
       " 'encoder_0/bidirectional_rnn/bw/lstm_cell/bias/read',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/lstm_cell/concat/axis',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/lstm_cell/concat',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/lstm_cell/MatMul/Enter',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/lstm_cell/MatMul',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/lstm_cell/BiasAdd/Enter',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/lstm_cell/BiasAdd',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/lstm_cell/Const',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/lstm_cell/split/split_dim',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/lstm_cell/split',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/lstm_cell/add/y',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/lstm_cell/add',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/lstm_cell/Sigmoid',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/lstm_cell/mul',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/lstm_cell/Sigmoid_1',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/lstm_cell/Tanh',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/lstm_cell/mul_1',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/lstm_cell/add_1',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/lstm_cell/Sigmoid_2',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/lstm_cell/Tanh_1',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/lstm_cell/mul_2',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/Select/Enter',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/Select',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/Select_1',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/Select_2',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/TensorArrayWrite/TensorArrayWriteV3/Enter',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/TensorArrayWrite/TensorArrayWriteV3',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/add_1/y',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/add_1',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/NextIteration',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/NextIteration_1',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/NextIteration_2',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/NextIteration_3',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/NextIteration_4',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/Exit',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/Exit_1',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/Exit_2',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/Exit_3',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/Exit_4',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/TensorArrayStack/TensorArraySizeV3',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/TensorArrayStack/range/start',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/TensorArrayStack/range/delta',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/TensorArrayStack/range',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/TensorArrayStack/TensorArrayGatherV3',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/Const_4',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/Rank_1',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/range_1/start',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/range_1/delta',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/range_1',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/concat_2/values_0',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/concat_2/axis',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/concat_2',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/transpose_1',\n",
       " 'encoder_0/ReverseSequence',\n",
       " 'encoder_1/DropoutWrapperInit/Const',\n",
       " 'encoder_1/DropoutWrapperInit/Const_1',\n",
       " 'encoder_1/DropoutWrapperInit_1/Const',\n",
       " 'encoder_1/DropoutWrapperInit_1/Const_1',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/Rank',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/range/start',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/range/delta',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/range',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/concat/values_0',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/concat/axis',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/concat',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/transpose',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/sequence_length',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/Shape',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/strided_slice/stack',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/strided_slice/stack_1',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/strided_slice/stack_2',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/strided_slice',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/ExpandDims/dim',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/ExpandDims',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/Const',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/concat/axis',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/concat',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/zeros/Const',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/zeros',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/ExpandDims_1/dim',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/ExpandDims_1',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/Const_1',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/ExpandDims_2/dim',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/ExpandDims_2',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/Const_2',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/concat_1/axis',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/concat_1',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/zeros_1/Const',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/zeros_1',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/ExpandDims_3/dim',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/ExpandDims_3',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/Const_3',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/Shape_1',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/stack',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/Equal',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/Const',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/All',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/Assert/Const',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/Assert/Const_1',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/Assert/Assert/data_0',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/Assert/Assert/data_2',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/Assert/Assert',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/CheckSeqLen',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/Shape_2',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/strided_slice_1/stack',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/strided_slice_1/stack_1',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/strided_slice_1/stack_2',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/strided_slice_1',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/Shape_3',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/strided_slice_2/stack',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/strided_slice_2/stack_1',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/strided_slice_2/stack_2',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/strided_slice_2',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/ExpandDims/dim',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/ExpandDims',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/Const_1',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/concat_1/axis',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/concat_1',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/zeros/Const',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/zeros',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/Const_2',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/Min',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/Const_3',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/Max',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/time',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/TensorArray',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/TensorArray_1',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/TensorArrayUnstack/Shape',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/TensorArrayUnstack/strided_slice/stack',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/TensorArrayUnstack/strided_slice/stack_1',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/TensorArrayUnstack/strided_slice/stack_2',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/TensorArrayUnstack/strided_slice',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/TensorArrayUnstack/range/start',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/TensorArrayUnstack/range/delta',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/TensorArrayUnstack/range',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/Maximum/x',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/Maximum',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/Minimum',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/iteration_counter',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/Enter',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/Enter_1',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/Enter_2',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/Enter_3',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/Enter_4',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/Merge',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/Merge_1',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/Merge_2',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/Merge_3',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/Merge_4',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/Less/Enter',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/Less',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/Less_1/Enter',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/Less_1',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/LogicalAnd',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/LoopCond',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/Switch',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/Switch_1',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/Switch_2',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/Switch_3',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/Switch_4',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/Identity',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/Identity_1',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/Identity_2',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/Identity_3',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/Identity_4',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/add/y',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/add',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/TensorArrayReadV3/Enter',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/TensorArrayReadV3/Enter_1',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/TensorArrayReadV3',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/GreaterEqual/Enter',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/GreaterEqual',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/sub/x',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/sub/Enter',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/sub',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/dropout/Shape',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/dropout/random_uniform/min',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/dropout/random_uniform/max',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/dropout/random_uniform/RandomUniform',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/dropout/random_uniform/sub',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/dropout/random_uniform/mul',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/dropout/random_uniform',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/dropout/sub/x',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/dropout/sub',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/dropout/truediv/x',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/dropout/truediv',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/dropout/GreaterEqual',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/dropout/mul',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/dropout/Cast',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/dropout/mul_1',\n",
       " 'encoder_1/bidirectional_rnn/fw/lstm_cell/kernel/Initializer/random_uniform/shape',\n",
       " 'encoder_1/bidirectional_rnn/fw/lstm_cell/kernel/Initializer/random_uniform/min',\n",
       " 'encoder_1/bidirectional_rnn/fw/lstm_cell/kernel/Initializer/random_uniform/max',\n",
       " 'encoder_1/bidirectional_rnn/fw/lstm_cell/kernel/Initializer/random_uniform/RandomUniform',\n",
       " 'encoder_1/bidirectional_rnn/fw/lstm_cell/kernel/Initializer/random_uniform/sub',\n",
       " 'encoder_1/bidirectional_rnn/fw/lstm_cell/kernel/Initializer/random_uniform/mul',\n",
       " 'encoder_1/bidirectional_rnn/fw/lstm_cell/kernel/Initializer/random_uniform',\n",
       " 'encoder_1/bidirectional_rnn/fw/lstm_cell/kernel',\n",
       " 'encoder_1/bidirectional_rnn/fw/lstm_cell/kernel/Assign',\n",
       " 'encoder_1/bidirectional_rnn/fw/lstm_cell/kernel/read',\n",
       " 'encoder_1/bidirectional_rnn/fw/lstm_cell/bias/Initializer/zeros/shape_as_tensor',\n",
       " 'encoder_1/bidirectional_rnn/fw/lstm_cell/bias/Initializer/zeros/Const',\n",
       " 'encoder_1/bidirectional_rnn/fw/lstm_cell/bias/Initializer/zeros',\n",
       " 'encoder_1/bidirectional_rnn/fw/lstm_cell/bias',\n",
       " 'encoder_1/bidirectional_rnn/fw/lstm_cell/bias/Assign',\n",
       " 'encoder_1/bidirectional_rnn/fw/lstm_cell/bias/read',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/lstm_cell/concat/axis',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/lstm_cell/concat',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/lstm_cell/MatMul/Enter',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/lstm_cell/MatMul',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/lstm_cell/BiasAdd/Enter',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/lstm_cell/BiasAdd',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/lstm_cell/Const',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/lstm_cell/split/split_dim',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/lstm_cell/split',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/lstm_cell/add/y',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/lstm_cell/add',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/lstm_cell/Sigmoid',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/lstm_cell/mul',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/lstm_cell/Sigmoid_1',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/lstm_cell/Tanh',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/lstm_cell/mul_1',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/lstm_cell/add_1',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/lstm_cell/Sigmoid_2',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/lstm_cell/Tanh_1',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/lstm_cell/mul_2',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/Select/Enter',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/Select',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/Select_1',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/Select_2',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/TensorArrayWrite/TensorArrayWriteV3/Enter',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/TensorArrayWrite/TensorArrayWriteV3',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/add_1/y',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/add_1',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/NextIteration',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/NextIteration_1',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/NextIteration_2',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/NextIteration_3',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/NextIteration_4',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/Exit',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/Exit_1',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/Exit_2',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/Exit_3',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/Exit_4',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/TensorArrayStack/TensorArraySizeV3',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/TensorArrayStack/range/start',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/TensorArrayStack/range/delta',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/TensorArrayStack/range',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/TensorArrayStack/TensorArrayGatherV3',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/Const_4',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/Rank_1',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/range_1/start',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/range_1/delta',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/range_1',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/concat_2/values_0',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/concat_2/axis',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/concat_2',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/transpose_1',\n",
       " 'encoder_1/bidirectional_rnn/bw/ReverseSequence',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/Rank',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/range/start',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/range/delta',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/range',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/concat/values_0',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/concat/axis',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/concat',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/transpose',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/sequence_length',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/Shape',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/strided_slice/stack',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/strided_slice/stack_1',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/strided_slice/stack_2',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/strided_slice',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/ExpandDims/dim',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/ExpandDims',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/Const',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/concat/axis',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/concat',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/zeros/Const',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/zeros',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/ExpandDims_1/dim',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/ExpandDims_1',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/Const_1',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/ExpandDims_2/dim',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/ExpandDims_2',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/Const_2',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/concat_1/axis',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/concat_1',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/zeros_1/Const',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/zeros_1',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/ExpandDims_3/dim',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/ExpandDims_3',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/Const_3',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/Shape_1',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/stack',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/Equal',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/Const',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/All',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/Assert/Const',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/Assert/Const_1',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/Assert/Assert/data_0',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/Assert/Assert/data_2',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/Assert/Assert',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/CheckSeqLen',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/Shape_2',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/strided_slice_1/stack',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/strided_slice_1/stack_1',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/strided_slice_1/stack_2',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/strided_slice_1',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/Shape_3',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/strided_slice_2/stack',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/strided_slice_2/stack_1',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/strided_slice_2/stack_2',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/strided_slice_2',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/ExpandDims/dim',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/ExpandDims',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/Const_1',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/concat_1/axis',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/concat_1',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/zeros/Const',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/zeros',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/Const_2',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/Min',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/Const_3',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/Max',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/time',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/TensorArray',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/TensorArray_1',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/TensorArrayUnstack/Shape',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/TensorArrayUnstack/strided_slice/stack',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/TensorArrayUnstack/strided_slice/stack_1',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/TensorArrayUnstack/strided_slice/stack_2',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/TensorArrayUnstack/strided_slice',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/TensorArrayUnstack/range/start',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/TensorArrayUnstack/range/delta',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/TensorArrayUnstack/range',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/Maximum/x',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/Maximum',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/Minimum',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/iteration_counter',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/Enter',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/Enter_1',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/Enter_2',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/Enter_3',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/Enter_4',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/Merge',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/Merge_1',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/Merge_2',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/Merge_3',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/Merge_4',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/Less/Enter',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/Less',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/Less_1/Enter',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/Less_1',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/LogicalAnd',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/LoopCond',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/Switch',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/Switch_1',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/Switch_2',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/Switch_3',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/Switch_4',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/Identity',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/Identity_1',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/Identity_2',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/Identity_3',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/Identity_4',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/add/y',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/add',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/TensorArrayReadV3/Enter',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/TensorArrayReadV3/Enter_1',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/TensorArrayReadV3',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/GreaterEqual/Enter',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/GreaterEqual',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/sub/x',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/sub/Enter',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/sub',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/dropout/Shape',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/dropout/random_uniform/min',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/dropout/random_uniform/max',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/dropout/random_uniform/RandomUniform',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/dropout/random_uniform/sub',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/dropout/random_uniform/mul',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/dropout/random_uniform',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/dropout/sub/x',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/dropout/sub',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/dropout/truediv/x',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/dropout/truediv',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/dropout/GreaterEqual',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/dropout/mul',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/dropout/Cast',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/dropout/mul_1',\n",
       " 'encoder_1/bidirectional_rnn/bw/lstm_cell/kernel/Initializer/random_uniform/shape',\n",
       " 'encoder_1/bidirectional_rnn/bw/lstm_cell/kernel/Initializer/random_uniform/min',\n",
       " 'encoder_1/bidirectional_rnn/bw/lstm_cell/kernel/Initializer/random_uniform/max',\n",
       " 'encoder_1/bidirectional_rnn/bw/lstm_cell/kernel/Initializer/random_uniform/RandomUniform',\n",
       " 'encoder_1/bidirectional_rnn/bw/lstm_cell/kernel/Initializer/random_uniform/sub',\n",
       " 'encoder_1/bidirectional_rnn/bw/lstm_cell/kernel/Initializer/random_uniform/mul',\n",
       " 'encoder_1/bidirectional_rnn/bw/lstm_cell/kernel/Initializer/random_uniform',\n",
       " 'encoder_1/bidirectional_rnn/bw/lstm_cell/kernel',\n",
       " 'encoder_1/bidirectional_rnn/bw/lstm_cell/kernel/Assign',\n",
       " 'encoder_1/bidirectional_rnn/bw/lstm_cell/kernel/read',\n",
       " 'encoder_1/bidirectional_rnn/bw/lstm_cell/bias/Initializer/zeros/shape_as_tensor',\n",
       " 'encoder_1/bidirectional_rnn/bw/lstm_cell/bias/Initializer/zeros/Const',\n",
       " 'encoder_1/bidirectional_rnn/bw/lstm_cell/bias/Initializer/zeros',\n",
       " 'encoder_1/bidirectional_rnn/bw/lstm_cell/bias',\n",
       " 'encoder_1/bidirectional_rnn/bw/lstm_cell/bias/Assign',\n",
       " 'encoder_1/bidirectional_rnn/bw/lstm_cell/bias/read',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/lstm_cell/concat/axis',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/lstm_cell/concat',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/lstm_cell/MatMul/Enter',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/lstm_cell/MatMul',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/lstm_cell/BiasAdd/Enter',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/lstm_cell/BiasAdd',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/lstm_cell/Const',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/lstm_cell/split/split_dim',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/lstm_cell/split',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/lstm_cell/add/y',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/lstm_cell/add',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/lstm_cell/Sigmoid',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/lstm_cell/mul',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/lstm_cell/Sigmoid_1',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/lstm_cell/Tanh',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/lstm_cell/mul_1',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/lstm_cell/add_1',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/lstm_cell/Sigmoid_2',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/lstm_cell/Tanh_1',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/lstm_cell/mul_2',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/Select/Enter',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/Select',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/Select_1',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/Select_2',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/TensorArrayWrite/TensorArrayWriteV3/Enter',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/TensorArrayWrite/TensorArrayWriteV3',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/add_1/y',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/add_1',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/NextIteration',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/NextIteration_1',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/NextIteration_2',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/NextIteration_3',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/NextIteration_4',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/Exit',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/Exit_1',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/Exit_2',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/Exit_3',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/Exit_4',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/TensorArrayStack/TensorArraySizeV3',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/TensorArrayStack/range/start',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/TensorArrayStack/range/delta',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/TensorArrayStack/range',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/TensorArrayStack/TensorArrayGatherV3',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/Const_4',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/Rank_1',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/range_1/start',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/range_1/delta',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/range_1',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/concat_2/values_0',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/concat_2/axis',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/concat_2',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/transpose_1',\n",
       " 'encoder_1/ReverseSequence',\n",
       " 'concat/axis',\n",
       " 'concat',\n",
       " 'StridedSlice/begin',\n",
       " 'StridedSlice/end',\n",
       " 'StridedSlice/strides',\n",
       " 'StridedSlice',\n",
       " 'Fill/dims',\n",
       " 'Fill/value',\n",
       " 'Fill',\n",
       " 'concat_1/axis',\n",
       " 'concat_1',\n",
       " 'embedding_lookup_1/params_0',\n",
       " 'embedding_lookup_1/axis',\n",
       " 'embedding_lookup_1',\n",
       " 'embedding_lookup_1/Identity',\n",
       " 'decoder_0/DropoutWrapperInit/Const',\n",
       " 'decoder_0/DropoutWrapperInit/Const_1',\n",
       " 'decoder_1/DropoutWrapperInit/Const',\n",
       " 'decoder_1/DropoutWrapperInit/Const_1',\n",
       " 'BahdanauAttention/Shape',\n",
       " 'BahdanauAttention/strided_slice/stack',\n",
       " 'BahdanauAttention/strided_slice/stack_1',\n",
       " 'BahdanauAttention/strided_slice/stack_2',\n",
       " 'BahdanauAttention/strided_slice',\n",
       " 'BahdanauAttention/SequenceMask/Const',\n",
       " 'BahdanauAttention/SequenceMask/Const_1',\n",
       " 'BahdanauAttention/SequenceMask/Range',\n",
       " 'BahdanauAttention/SequenceMask/ExpandDims/dim',\n",
       " 'BahdanauAttention/SequenceMask/ExpandDims',\n",
       " 'BahdanauAttention/SequenceMask/Cast',\n",
       " 'BahdanauAttention/SequenceMask/Less',\n",
       " 'BahdanauAttention/SequenceMask/Cast_1',\n",
       " 'BahdanauAttention/ones/shape_as_tensor',\n",
       " 'BahdanauAttention/ones/Const',\n",
       " 'BahdanauAttention/ones',\n",
       " 'BahdanauAttention/Shape_1',\n",
       " 'BahdanauAttention/concat/axis',\n",
       " 'BahdanauAttention/concat',\n",
       " 'BahdanauAttention/Reshape',\n",
       " 'BahdanauAttention/mul',\n",
       " 'memory_layer/kernel/Initializer/random_uniform/shape',\n",
       " 'memory_layer/kernel/Initializer/random_uniform/min',\n",
       " 'memory_layer/kernel/Initializer/random_uniform/max',\n",
       " 'memory_layer/kernel/Initializer/random_uniform/RandomUniform',\n",
       " 'memory_layer/kernel/Initializer/random_uniform/sub',\n",
       " 'memory_layer/kernel/Initializer/random_uniform/mul',\n",
       " 'memory_layer/kernel/Initializer/random_uniform',\n",
       " 'memory_layer/kernel',\n",
       " 'memory_layer/kernel/Assign',\n",
       " 'memory_layer/kernel/read',\n",
       " 'BahdanauAttention/memory_layer/Tensordot/axes',\n",
       " 'BahdanauAttention/memory_layer/Tensordot/free',\n",
       " 'BahdanauAttention/memory_layer/Tensordot/Shape',\n",
       " 'BahdanauAttention/memory_layer/Tensordot/GatherV2/axis',\n",
       " 'BahdanauAttention/memory_layer/Tensordot/GatherV2',\n",
       " 'BahdanauAttention/memory_layer/Tensordot/GatherV2_1/axis',\n",
       " 'BahdanauAttention/memory_layer/Tensordot/GatherV2_1',\n",
       " 'BahdanauAttention/memory_layer/Tensordot/Const',\n",
       " 'BahdanauAttention/memory_layer/Tensordot/Prod',\n",
       " 'BahdanauAttention/memory_layer/Tensordot/Const_1',\n",
       " 'BahdanauAttention/memory_layer/Tensordot/Prod_1',\n",
       " 'BahdanauAttention/memory_layer/Tensordot/concat/axis',\n",
       " 'BahdanauAttention/memory_layer/Tensordot/concat',\n",
       " 'BahdanauAttention/memory_layer/Tensordot/stack',\n",
       " 'BahdanauAttention/memory_layer/Tensordot/transpose',\n",
       " 'BahdanauAttention/memory_layer/Tensordot/Reshape',\n",
       " 'BahdanauAttention/memory_layer/Tensordot/transpose_1/perm',\n",
       " 'BahdanauAttention/memory_layer/Tensordot/transpose_1',\n",
       " 'BahdanauAttention/memory_layer/Tensordot/Reshape_1/shape',\n",
       " 'BahdanauAttention/memory_layer/Tensordot/Reshape_1',\n",
       " 'BahdanauAttention/memory_layer/Tensordot/MatMul',\n",
       " 'BahdanauAttention/memory_layer/Tensordot/Const_2',\n",
       " 'BahdanauAttention/memory_layer/Tensordot/concat_1/axis',\n",
       " 'BahdanauAttention/memory_layer/Tensordot/concat_1',\n",
       " 'BahdanauAttention/memory_layer/Tensordot',\n",
       " 'BahdanauAttention/Shape_2',\n",
       " 'BahdanauAttention/strided_slice_1/stack',\n",
       " 'BahdanauAttention/strided_slice_1/stack_1',\n",
       " 'BahdanauAttention/strided_slice_1/stack_2',\n",
       " 'BahdanauAttention/strided_slice_1',\n",
       " 'BahdanauAttention/Shape_3',\n",
       " 'BahdanauAttention/strided_slice_2/stack',\n",
       " 'BahdanauAttention/strided_slice_2/stack_1',\n",
       " 'BahdanauAttention/strided_slice_2/stack_2',\n",
       " 'BahdanauAttention/strided_slice_2',\n",
       " 'AttentionWrapperZeroState/DropoutWrapperZeroState/LSTMCellZeroState/Const',\n",
       " 'AttentionWrapperZeroState/DropoutWrapperZeroState/LSTMCellZeroState/Const_1',\n",
       " 'AttentionWrapperZeroState/DropoutWrapperZeroState/LSTMCellZeroState/concat/axis',\n",
       " 'AttentionWrapperZeroState/DropoutWrapperZeroState/LSTMCellZeroState/concat',\n",
       " 'AttentionWrapperZeroState/DropoutWrapperZeroState/LSTMCellZeroState/zeros/Const',\n",
       " 'AttentionWrapperZeroState/DropoutWrapperZeroState/LSTMCellZeroState/zeros',\n",
       " 'AttentionWrapperZeroState/DropoutWrapperZeroState/LSTMCellZeroState/Const_2',\n",
       " 'AttentionWrapperZeroState/DropoutWrapperZeroState/LSTMCellZeroState/Const_3',\n",
       " 'AttentionWrapperZeroState/DropoutWrapperZeroState/LSTMCellZeroState/Const_4',\n",
       " 'AttentionWrapperZeroState/DropoutWrapperZeroState/LSTMCellZeroState/Const_5',\n",
       " 'AttentionWrapperZeroState/DropoutWrapperZeroState/LSTMCellZeroState/concat_1/axis',\n",
       " 'AttentionWrapperZeroState/DropoutWrapperZeroState/LSTMCellZeroState/concat_1',\n",
       " 'AttentionWrapperZeroState/DropoutWrapperZeroState/LSTMCellZeroState/zeros_1/Const',\n",
       " 'AttentionWrapperZeroState/DropoutWrapperZeroState/LSTMCellZeroState/zeros_1',\n",
       " 'AttentionWrapperZeroState/DropoutWrapperZeroState/LSTMCellZeroState/Const_6',\n",
       " 'AttentionWrapperZeroState/DropoutWrapperZeroState/LSTMCellZeroState/Const_7',\n",
       " 'AttentionWrapperZeroState/assert_equal/x',\n",
       " 'AttentionWrapperZeroState/assert_equal/Equal',\n",
       " 'AttentionWrapperZeroState/assert_equal/Const',\n",
       " 'AttentionWrapperZeroState/assert_equal/All',\n",
       " 'AttentionWrapperZeroState/assert_equal/Assert/Const',\n",
       " 'AttentionWrapperZeroState/assert_equal/Assert/Const_1',\n",
       " 'AttentionWrapperZeroState/assert_equal/Assert/Const_2',\n",
       " 'AttentionWrapperZeroState/assert_equal/Assert/Const_3',\n",
       " 'AttentionWrapperZeroState/assert_equal/Assert/Assert/data_0',\n",
       " 'AttentionWrapperZeroState/assert_equal/Assert/Assert/data_1',\n",
       " 'AttentionWrapperZeroState/assert_equal/Assert/Assert/data_2',\n",
       " 'AttentionWrapperZeroState/assert_equal/Assert/Assert/data_4',\n",
       " 'AttentionWrapperZeroState/assert_equal/Assert/Assert',\n",
       " 'AttentionWrapperZeroState/checked_cell_state',\n",
       " 'AttentionWrapperZeroState/checked_cell_state_1',\n",
       " 'AttentionWrapperZeroState/Const',\n",
       " 'AttentionWrapperZeroState/ExpandDims/dim',\n",
       " 'AttentionWrapperZeroState/ExpandDims',\n",
       " 'AttentionWrapperZeroState/concat/axis',\n",
       " 'AttentionWrapperZeroState/concat',\n",
       " 'AttentionWrapperZeroState/zeros/Const',\n",
       " 'AttentionWrapperZeroState/zeros',\n",
       " 'AttentionWrapperZeroState/Const_1',\n",
       " 'AttentionWrapperZeroState/ExpandDims_1/dim',\n",
       " 'AttentionWrapperZeroState/ExpandDims_1',\n",
       " 'AttentionWrapperZeroState/zeros_1',\n",
       " 'AttentionWrapperZeroState/Const_2',\n",
       " 'AttentionWrapperZeroState/Const_3',\n",
       " 'AttentionWrapperZeroState/concat_1/axis',\n",
       " 'AttentionWrapperZeroState/concat_1',\n",
       " 'AttentionWrapperZeroState/zeros_2/Const',\n",
       " 'AttentionWrapperZeroState/zeros_2',\n",
       " 'AttentionWrapperZeroState/Const_4',\n",
       " 'AttentionWrapperZeroState/Const_5',\n",
       " 'AttentionWrapperZeroState/Const_6',\n",
       " 'AttentionWrapperZeroState/ExpandDims_2/dim',\n",
       " 'AttentionWrapperZeroState/ExpandDims_2',\n",
       " 'AttentionWrapperZeroState/concat_2/axis',\n",
       " 'AttentionWrapperZeroState/concat_2',\n",
       " 'AttentionWrapperZeroState/zeros_3/Const',\n",
       " 'AttentionWrapperZeroState/zeros_3',\n",
       " 'AttentionWrapperZeroState/Const_7',\n",
       " 'AttentionWrapperZeroState/ExpandDims_3/dim',\n",
       " 'AttentionWrapperZeroState/ExpandDims_3',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/Exit_3/assert_shape/actual',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/Exit_3/assert_shape/is_shape/Size/Const',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/Exit_3/assert_shape/is_shape/Size',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/Exit_3/assert_shape/is_shape/is_rank/actual',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/Exit_3/assert_shape/is_shape/is_rank',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/Exit_3/assert_shape/is_shape/shape_tensor_equal/Equal/x',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/Exit_3/assert_shape/is_shape/shape_tensor_equal/Equal/y',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/Exit_3/assert_shape/is_shape/shape_tensor_equal/Equal',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/Exit_3/assert_shape/is_shape/shape_tensor_equal/equal_1/x',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/Exit_3/assert_shape/is_shape/shape_tensor_equal/equal_1',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/Exit_3/assert_shape/is_shape/shape_tensor_equal/exclude_partial_shape',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/Exit_3/assert_shape/is_shape/shape_tensor_equal/Const',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/Exit_3/assert_shape/is_shape/shape_tensor_equal',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/Exit_3/assert_shape/is_shape',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/Exit_3/assert_shape/Const',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/Exit_3/assert_shape/Const_1',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/Exit_3/assert_shape/Assert/data_0',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/Exit_3/assert_shape/Assert/data_1',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/Exit_3/assert_shape/Assert',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/Exit_3/Identity',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/Exit_4/assert_shape/actual',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/Exit_4/assert_shape/is_shape/Size/Const',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/Exit_4/assert_shape/is_shape/Size',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/Exit_4/assert_shape/is_shape/is_rank/actual',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/Exit_4/assert_shape/is_shape/is_rank',\n",
       " ...]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = \"checkpoints/best_model.ckpt\" \n",
    "\n",
    "loaded_graph = tf.Graph()\n",
    "with tf.Session(graph=loaded_graph) as sess:\n",
    "    # Load saved model\n",
    "    loader = tf.train.import_meta_graph(checkpoint + '.meta')\n",
    "    loader.restore(sess, checkpoint)\n",
    "    names = []\n",
    "    [names.append(n.name) for n in loaded_graph.as_graph_def().node]\n",
    "names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_seq(text):\n",
    "    '''Prepare the text for the model'''\n",
    "    return [vocab_to_int.get(word, vocab_to_int['<UNK>']) for word in text.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/best_model.ckpt\n",
      "\n",
      "==================== Example 0 ====================\n",
      "Original Text:\n",
      "anything else stop sum artist think translate online profile words twitter allows entire page indulgence website would allow bring salient features creativity experience passion reasons painting make clear readers artist loves art produces high quality art true champion art great words find friend help really important aspect selling online – establishment credibility reliability\n",
      "\n",
      "Original Summary:\n",
      "sell yourself first \n",
      "\n",
      "Input:\n",
      "Word Ids: [77, 78, 79, 80, 9, 81, 82, 8, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 11, 101, 102, 9, 103, 29, 104, 105, 106, 29, 107, 108, 29, 109, 84, 110, 111, 112, 113, 114, 115, 116, 8, 1103, 117, 118, 119]\n",
      "anything else stop sum artist think translate online profile words twitter allows entire page indulgence website would allow bring salient features creativity experience passion reasons painting make clear readers artist loves art produces high quality art true champion art great words find friend help really important aspect selling online <UNK> establishment credibility reliability\n",
      "\n",
      "Output Summary:\n",
      "Word Ids: [0, 1, 2]\n",
      "sell yourself first\n",
      "\n",
      "==================== Example 1 ====================\n",
      "Original Text:\n",
      "reading classics first thing well read want build solid foundation understanding books read cannot avoid earliest plays poems oral tales ever written remember novel really get popular 18th century find novels list without reading poetry homer plays sophocles able call well read list get started epic gilgamesh unknown author 18th – 17th century bce iliad odyssey homer 850–750 bce 8th century bce oresteia aeschylus 458 bce oedipus king sophocles 430 bce medea euripides 431 bce aeneid virgil 29–19 bce one thousand one nights unknown author 700–1500 beowulf unknown author 975 1025 tale genji murasaki shikibu 11th century divine comedy dante 1265–1321 decameron boccaccio 1349–53 canterbury tales chaucer 14th century\n",
      "\n",
      "Original Summary:\n",
      "read the classics before 1600 \n",
      "\n",
      "Input:\n",
      "Word Ids: [120, 5, 2, 121, 122, 3, 123, 124, 125, 126, 127, 128, 3, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 113, 140, 74, 1103, 141, 110, 142, 20, 143, 120, 144, 145, 132, 146, 147, 148, 122, 3, 20, 140, 149, 150, 151, 152, 153, 1103, 1103, 1103, 141, 154, 155, 156, 145, 1103, 154, 157, 141, 154, 1103, 158, 1103, 154, 159, 160, 146, 1103, 154, 161, 162, 1103, 154, 163, 164, 1103, 154, 165, 166, 165, 167, 152, 153, 1103, 168, 152, 153, 1103, 1103, 169, 170, 171, 1103, 1103, 141, 172, 173, 174, 1103, 175, 176, 1103, 177, 135, 178, 1103, 141]\n",
      "reading classics first thing well read want build solid foundation understanding books read cannot avoid earliest plays poems oral tales ever written remember novel really get popular <UNK> century find novels list without reading poetry homer plays sophocles able call well read list get started epic gilgamesh unknown author <UNK> <UNK> <UNK> century bce iliad odyssey homer <UNK> bce 8th century bce <UNK> aeschylus <UNK> bce oedipus king sophocles <UNK> bce medea euripides <UNK> bce aeneid virgil <UNK> bce one thousand one nights unknown author <UNK> beowulf unknown author <UNK> <UNK> tale genji murasaki <UNK> <UNK> century divine comedy dante <UNK> decameron boccaccio <UNK> canterbury tales chaucer <UNK> century\n",
      "\n",
      "Output Summary:\n",
      "Word Ids: [3, 4, 5, 6, 1103]\n",
      "read the classics before <UNK>\n",
      "\n",
      "==================== Example 2 ====================\n",
      "Original Text:\n",
      "depending scale intend sell art pieces may want get account online art community store like deviant art 15 20 brokerage also find many online art galleries like art brokerage diva art group saatchi art show artwork online sell buyer completely secured transaction also many possible sites etsy heavier crafts still arty ebay auction site amazon store online store platform cafepress printing artwork onto stuff like mugs craigslist general classifieds quite lot artwork based sales sites general search read terms conditions every site carefully know commission percentage site takes know protections lack site offers know clientele generally peruse site know general sales brought site know everything relevant sales goal turn art investment property selling online likely much longer path end largely generally difficult unknown artists secure higher priced sales serious collectors online traditional gallery concrete decisions made safely best see selling art online adjunct usual methods selling art means\n",
      "\n",
      "Original Summary:\n",
      "join online artist communities \n",
      "\n",
      "Input:\n",
      "Word Ids: [179, 180, 181, 0, 29, 182, 183, 123, 140, 63, 8, 29, 184, 185, 186, 187, 29, 1103, 1103, 188, 189, 110, 190, 8, 29, 191, 186, 29, 188, 192, 29, 193, 1103, 29, 194, 16, 8, 0, 195, 196, 197, 198, 189, 190, 199, 200, 201, 202, 203, 204, 205, 206, 207, 35, 208, 185, 8, 185, 209, 1103, 210, 16, 211, 212, 186, 213, 214, 215, 216, 217, 43, 16, 218, 219, 200, 215, 220, 3, 221, 222, 223, 35, 224, 225, 226, 227, 35, 228, 225, 229, 230, 35, 231, 225, 232, 233, 234, 35, 225, 215, 219, 235, 35, 225, 236, 237, 219, 238, 239, 29, 240, 241, 116, 8, 242, 243, 244, 245, 246, 247, 233, 248, 152, 249, 250, 251, 252, 219, 253, 254, 8, 255, 256, 257, 258, 259, 260, 261, 262, 116, 29, 8, 263, 264, 265, 116, 29, 266]\n",
      "depending scale intend sell art pieces may want get account online art community store like deviant art <UNK> <UNK> brokerage also find many online art galleries like art brokerage diva art group <UNK> art show artwork online sell buyer completely secured transaction also many possible sites etsy heavier crafts still arty ebay auction site amazon store online store platform <UNK> printing artwork onto stuff like mugs craigslist general classifieds quite lot artwork based sales sites general search read terms conditions every site carefully know commission percentage site takes know protections lack site offers know clientele generally peruse site know general sales brought site know everything relevant sales goal turn art investment property selling online likely much longer path end largely generally difficult unknown artists secure higher priced sales serious collectors online traditional gallery concrete decisions made safely best see selling art online adjunct usual methods selling art means\n",
      "\n",
      "Output Summary:\n",
      "Word Ids: [7, 8, 9, 10]\n",
      "join online artist communities\n",
      "\n",
      "==================== Example 3 ====================\n",
      "Original Text:\n",
      "get best advertising publish example pieces around web show demonstrate style sure add watermark digital version protect artwork art thieves spend little time researching online ways artists promoting works like promotional strategies want avoid type research give lot ideas also alert potential pitfalls ways promote artwork bookmark sites artists selling online really inspire come back regularly see evolving succeeding seize power twitter facebook increase people knowledge tweet updates new paintings thoughts art news items art general facebook place photos artwork digitally watermarked photos receiving awards information art artwork general perhaps even critiques artwork\n",
      "\n",
      "Original Summary:\n",
      "make yourself public \n",
      "\n",
      "Input:\n",
      "Word Ids: [140, 261, 267, 268, 269, 182, 270, 271, 194, 272, 273, 25, 274, 275, 276, 277, 278, 16, 29, 279, 280, 281, 282, 283, 8, 284, 249, 285, 286, 186, 287, 288, 123, 130, 289, 290, 291, 43, 292, 189, 293, 294, 295, 284, 296, 16, 297, 200, 249, 116, 8, 113, 298, 299, 300, 301, 262, 302, 303, 304, 305, 85, 306, 307, 308, 309, 310, 311, 312, 313, 314, 29, 315, 316, 29, 215, 306, 317, 318, 16, 319, 320, 318, 321, 322, 323, 29, 16, 215, 324, 325, 326, 16]\n",
      "get best advertising publish example pieces around web show demonstrate style sure add watermark digital version protect artwork art thieves spend little time researching online ways artists promoting works like promotional strategies want avoid type research give lot ideas also alert potential pitfalls ways promote artwork bookmark sites artists selling online really inspire come back regularly see evolving succeeding seize power twitter facebook increase people knowledge tweet updates new paintings thoughts art news items art general facebook place photos artwork digitally watermarked photos receiving awards information art artwork general perhaps even critiques artwork\n",
      "\n",
      "Output Summary:\n",
      "Word Ids: [11, 1, 12]\n",
      "make yourself public\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== Example 4 ====================\n",
      "Original Text:\n",
      "given hundreds free blogging websites lot choice keeping blog importantly extremely useful keep updated regularly gives people something pretty look story follow reputation increases sales story grows blog pick lot hits search engines utilize keywords feature accurately use advantage sure name blog something simple memorable – want people able find ease read start blog increase website traffic free assistance good way test keywords little cost using auction site play around words use title art sales well words used within body text keep changing words find sweet spot – words really seem attract views\n",
      "\n",
      "Original Summary:\n",
      "blog about your artwork \n",
      "\n",
      "Input:\n",
      "Word Ids: [327, 328, 329, 330, 331, 43, 332, 333, 13, 334, 335, 336, 337, 338, 301, 339, 308, 340, 341, 64, 342, 343, 344, 345, 219, 342, 346, 13, 347, 43, 348, 220, 349, 350, 351, 352, 353, 354, 355, 25, 49, 13, 340, 356, 357, 1103, 123, 308, 147, 110, 358, 3, 359, 13, 307, 90, 360, 329, 361, 22, 362, 363, 351, 281, 364, 365, 207, 35, 366, 270, 84, 354, 367, 29, 219, 122, 84, 368, 369, 370, 371, 337, 372, 84, 110, 373, 374, 1103, 84, 113, 375, 376, 377]\n",
      "given hundreds free blogging websites lot choice keeping blog importantly extremely useful keep updated regularly gives people something pretty look story follow reputation increases sales story grows blog pick lot hits search engines utilize keywords feature accurately use advantage sure name blog something simple memorable <UNK> want people able find ease read start blog increase website traffic free assistance good way test keywords little cost using auction site play around words use title art sales well words used within body text keep changing words find sweet spot <UNK> words really seem attract views\n",
      "\n",
      "Output Summary:\n",
      "Word Ids: [13, 14, 15, 16]\n",
      "blog about your artwork\n",
      "\n",
      "==================== Example 5 ====================\n",
      "Original Text:\n",
      "could effective tool managed well every sale make every person sends email might interested get email addresses digital database ready mass emailing designated intervals month every week whenever start new series send nice grammatically correct friendly emails complete neatly set portfolio pictures recent work pdf work well purpose keeps radar past customers important really wonderful newsletter might get lucky might send friends well – even eyes seeing work every thoughtful mailing list includes opt option threatened see good housekeeping retaining clients really want see items online hassle people interested\n",
      "\n",
      "Original Summary:\n",
      "create a mailing list \n",
      "\n",
      "Input:\n",
      "Word Ids: [378, 379, 380, 381, 122, 223, 382, 11, 223, 383, 384, 385, 386, 387, 140, 385, 388, 276, 389, 390, 391, 392, 393, 394, 395, 223, 396, 397, 359, 312, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 23, 409, 410, 411, 410, 122, 412, 413, 414, 415, 416, 114, 113, 417, 418, 386, 140, 419, 386, 399, 420, 122, 1103, 325, 421, 422, 410, 223, 423, 19, 20, 424, 425, 31, 426, 262, 22, 427, 428, 429, 113, 123, 262, 316, 8, 430, 308, 387]\n",
      "could effective tool managed well every sale make every person sends email might interested get email addresses digital database ready mass emailing designated intervals month every week whenever start new series send nice grammatically correct friendly emails complete neatly set portfolio pictures recent work pdf work well purpose keeps radar past customers important really wonderful newsletter might get lucky might send friends well <UNK> even eyes seeing work every thoughtful mailing list includes opt option threatened see good housekeeping retaining clients really want see items online hassle people interested\n",
      "\n",
      "Output Summary:\n",
      "Word Ids: [0, 22, 23]\n",
      "sell good pictures\n"
     ]
    }
   ],
   "source": [
    "tests = [0, 1, 2, 3, 4, 5]\n",
    "\n",
    "checkpoint = \"checkpoints/best_model.ckpt\"\n",
    "\n",
    "loaded_graph = tf.Graph()\n",
    "with tf.Session(graph=loaded_graph) as sess:\n",
    "    # Load saved model\n",
    "    loader = tf.train.import_meta_graph(checkpoint + '.meta')\n",
    "    loader.restore(sess, checkpoint)\n",
    "\n",
    "    input_data = loaded_graph.get_tensor_by_name('input:0')\n",
    "    logits = loaded_graph.get_tensor_by_name('predictions:0')\n",
    "    text_length = loaded_graph.get_tensor_by_name('text_length:0')\n",
    "    summary_length = loaded_graph.get_tensor_by_name('summary_length:0')\n",
    "    keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
    "    for t in tests:\n",
    "        text = text_to_seq(texts[t])\n",
    "        #Multiply by batch_size to match the model's input parameters\n",
    "        answer_logits = sess.run(logits, {input_data: [text]*batch_size, \n",
    "                                      summary_length: [np.random.randint(5,8)], \n",
    "                                      text_length: [len(text)]*batch_size,\n",
    "                                      keep_prob: 1.0})[0] \n",
    "\n",
    "        # Remove the padding from the tweet\n",
    "        pad = vocab_to_int[\"<PAD>\"]\n",
    "        # print('Original Text:', wikihow.text[random])\n",
    "        # print('Original summary:', wikihow.summary[random])#clean_summaries[random]\n",
    "        print('\\n==================== Example {} ===================='.format(t))\n",
    "        print('Original Text:')\n",
    "        print(texts[t])\n",
    "        print('\\nOriginal Summary:')\n",
    "        print(summaries[t])\n",
    "        print('\\nInput:')\n",
    "        print('Word Ids: {}'.format([i for i in text]))\n",
    "        print('{}'.format(\" \".join([int_to_vocab[i] for i in text])))\n",
    "        print('\\nOutput Summary:')\n",
    "        print('Word Ids: {}'.format([i for i in answer_logits if i != pad]))\n",
    "        print('{}'.format(\" \".join([int_to_vocab[i] for i in answer_logits if i != pad])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
